From 174120b3fa2718ba97f25daa2e5c84d7a5482637 Mon Sep 17 00:00:00 2001
From: Oleksandr Natalenko <oleksandr@natalenko.name>
Date: Fri, 30 Apr 2021 08:20:30 +0200
Subject: [PATCH 6/6] zstd-5.12: update to submission v11

Signed-off-by: Oleksandr Natalenko <oleksandr@natalenko.name>
---
 include/linux/zstd_errors.h                  |   2 +-
 include/linux/zstd_lib.h                     | 108 +++++++++----------
 lib/zstd/common/compiler.h                   |   6 +-
 lib/zstd/common/cpu.h                        |   2 +-
 lib/zstd/common/fse.h                        |  28 ++---
 lib/zstd/common/huf.h                        |  70 ++++++------
 lib/zstd/common/zstd_internal.h              |  14 +--
 lib/zstd/compress/hist.h                     |   8 +-
 lib/zstd/compress/huf_compress.c             |   8 +-
 lib/zstd/compress/zstd_compress.c            |  30 +++---
 lib/zstd/compress/zstd_compress_internal.h   |  36 +++----
 lib/zstd/compress/zstd_compress_sequences.c  |  12 +--
 lib/zstd/compress/zstd_compress_superblock.c |  18 ++--
 lib/zstd/compress/zstd_cwksp.h               |  30 +++---
 lib/zstd/compress/zstd_lazy.c                |   6 +-
 lib/zstd/compress/zstd_lazy.h                |   2 +-
 lib/zstd/compress/zstd_ldm.c                 |  18 ++--
 lib/zstd/compress/zstd_ldm.h                 |  12 +--
 lib/zstd/compress/zstd_opt.c                 |   4 +-
 lib/zstd/decompress/huf_decompress.c         |   4 +-
 lib/zstd/decompress/zstd_decompress.c        |  28 ++---
 21 files changed, 223 insertions(+), 223 deletions(-)

diff --git a/include/linux/zstd_errors.h b/include/linux/zstd_errors.h
index da9fea781..58b6dd45a 100644
--- a/include/linux/zstd_errors.h
+++ b/include/linux/zstd_errors.h
@@ -70,7 +70,7 @@ typedef enum {
     convert a `size_t` function result into a `ZSTD_ErrorCode` enum type,
     which can be used to compare with enum list published above */
 ZSTDERRORLIB_API ZSTD_ErrorCode ZSTD_getErrorCode(size_t functionResult);
-ZSTDERRORLIB_API const char* ZSTD_getErrorString(ZSTD_ErrorCode code);   /**< Same as ZSTD_getErrorName, but using a `ZSTD_ErrorCode` enum argument */
+ZSTDERRORLIB_API const char* ZSTD_getErrorString(ZSTD_ErrorCode code);   /*< Same as ZSTD_getErrorName, but using a `ZSTD_ErrorCode` enum argument */
 
 
 
diff --git a/include/linux/zstd_lib.h b/include/linux/zstd_lib.h
index 2e6d0fb5d..b8c7dbf98 100644
--- a/include/linux/zstd_lib.h
+++ b/include/linux/zstd_lib.h
@@ -21,7 +21,7 @@
 #define ZSTDLIB_API ZSTDLIB_VISIBILITY
 
 
-/*******************************************************************************
+/* *****************************************************************************
   Introduction
 
   zstd, short for Zstandard, is a fast lossless compression algorithm, targeting
@@ -95,7 +95,7 @@ ZSTDLIB_API const char* ZSTD_versionString(void);
 
 
 
-/***************************************
+/* *************************************
 *  Simple API
 ***************************************/
 /*! ZSTD_compress() :
@@ -169,7 +169,7 @@ ZSTDLIB_API int         ZSTD_minCLevel(void);               /*!< minimum negativ
 ZSTDLIB_API int         ZSTD_maxCLevel(void);               /*!< maximum compression level available */
 
 
-/***************************************
+/* *************************************
 *  Explicit context
 ***************************************/
 /*= Compression context
@@ -219,7 +219,7 @@ ZSTDLIB_API size_t ZSTD_decompressDCtx(ZSTD_DCtx* dctx,
                                  const void* src, size_t srcSize);
 
 
-/***************************************
+/* *************************************
 *  Advanced compression API
 ***************************************/
 
@@ -504,7 +504,7 @@ ZSTDLIB_API size_t ZSTD_compress2( ZSTD_CCtx* cctx,
                              const void* src, size_t srcSize);
 
 
-/***************************************
+/* *************************************
 *  Advanced decompression API
 ***************************************/
 
@@ -569,20 +569,20 @@ ZSTDLIB_API size_t ZSTD_DCtx_setParameter(ZSTD_DCtx* dctx, ZSTD_dParameter param
 ZSTDLIB_API size_t ZSTD_DCtx_reset(ZSTD_DCtx* dctx, ZSTD_ResetDirective reset);
 
 
-/****************************
+/* **************************
 *  Streaming
 ****************************/
 
 typedef struct ZSTD_inBuffer_s {
-  const void* src;    /**< start of input buffer */
-  size_t size;        /**< size of input buffer */
-  size_t pos;         /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */
+  const void* src;    /*< start of input buffer */
+  size_t size;        /*< size of input buffer */
+  size_t pos;         /*< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */
 } ZSTD_inBuffer;
 
 typedef struct ZSTD_outBuffer_s {
-  void*  dst;         /**< start of output buffer */
-  size_t size;        /**< size of output buffer */
-  size_t pos;         /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */
+  void*  dst;         /*< start of output buffer */
+  size_t size;        /*< size of output buffer */
+  size_t pos;         /*< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */
 } ZSTD_outBuffer;
 
 
@@ -648,7 +648,7 @@ typedef struct ZSTD_outBuffer_s {
 *
 * *******************************************************************/
 
-typedef ZSTD_CCtx ZSTD_CStream;  /**< CCtx and CStream are now effectively same object (>= v1.3.0) */
+typedef ZSTD_CCtx ZSTD_CStream;  /*< CCtx and CStream are now effectively same object (>= v1.3.0) */
                                  /* Continue to distinguish them for compatibility with older versions <= v1.2.0 */
 /*===== ZSTD_CStream management functions =====*/
 ZSTDLIB_API ZSTD_CStream* ZSTD_createCStream(void);
@@ -709,8 +709,8 @@ ZSTDLIB_API size_t ZSTD_compressStream2( ZSTD_CCtx* cctx,
  * In which cases, prefer using large buffers, as large as practical,
  * for both input and output, to reduce the nb of roundtrips.
  */
-ZSTDLIB_API size_t ZSTD_CStreamInSize(void);    /**< recommended size for input buffer */
-ZSTDLIB_API size_t ZSTD_CStreamOutSize(void);   /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block. */
+ZSTDLIB_API size_t ZSTD_CStreamInSize(void);    /*< recommended size for input buffer */
+ZSTDLIB_API size_t ZSTD_CStreamOutSize(void);   /*< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block. */
 
 
 /* *****************************************************************************
@@ -769,7 +769,7 @@ ZSTDLIB_API size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);
 *                                that will never request more than the remaining frame size.
 * *******************************************************************************/
 
-typedef ZSTD_DCtx ZSTD_DStream;  /**< DCtx and DStream are now effectively same object (>= v1.3.0) */
+typedef ZSTD_DCtx ZSTD_DStream;  /*< DCtx and DStream are now effectively same object (>= v1.3.0) */
                                  /* For compatibility with versions <= v1.2.0, prefer differentiating them. */
 /*===== ZSTD_DStream management functions =====*/
 ZSTDLIB_API ZSTD_DStream* ZSTD_createDStream(void);
@@ -790,7 +790,7 @@ ZSTDLIB_API size_t ZSTD_DStreamInSize(void);    /*!< recommended size for input
 ZSTDLIB_API size_t ZSTD_DStreamOutSize(void);   /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */
 
 
-/**************************
+/* ************************
 *  Simple dictionary API
 ***************************/
 /*! ZSTD_compress_usingDict() :
@@ -818,7 +818,7 @@ ZSTDLIB_API size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,
                                        const void* dict,size_t dictSize);
 
 
-/***********************************
+/* *********************************
  *  Bulk processing dictionary API
  **********************************/
 typedef struct ZSTD_CDict_s ZSTD_CDict;
@@ -875,7 +875,7 @@ ZSTDLIB_API size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,
                                         const ZSTD_DDict* ddict);
 
 
-/********************************
+/* ******************************
  *  Dictionary helper functions
  *******************************/
 
@@ -904,7 +904,7 @@ ZSTDLIB_API unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);
 ZSTDLIB_API unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);
 
 
-/*******************************************************************************
+/* *****************************************************************************
  * Advanced dictionary and prefix API
  *
  * This API allows dictionaries to be used with ZSTD_compress2(),
@@ -1049,7 +1049,7 @@ ZSTDLIB_API size_t ZSTD_sizeof_DDict(const ZSTD_DDict* ddict);
 #if !defined(ZSTD_H_ZSTD_STATIC_LINKING_ONLY)
 #define ZSTD_H_ZSTD_STATIC_LINKING_ONLY
 
-/****************************************************************************************
+/* **************************************************************************************
  *   experimental API (static linking only)
  ****************************************************************************************
  * The following symbols and constants
@@ -1157,19 +1157,19 @@ typedef struct {
 } ZSTD_Sequence;
 
 typedef struct {
-    unsigned windowLog;       /**< largest match distance : larger == more compression, more memory needed during decompression */
-    unsigned chainLog;        /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */
-    unsigned hashLog;         /**< dispatch table : larger == faster, more memory */
-    unsigned searchLog;       /**< nb of searches : larger == more compression, slower */
-    unsigned minMatch;        /**< match length searched : larger == faster decompression, sometimes less compression */
-    unsigned targetLength;    /**< acceptable match size for optimal parser (only) : larger == more compression, slower */
-    ZSTD_strategy strategy;   /**< see ZSTD_strategy definition above */
+    unsigned windowLog;       /*< largest match distance : larger == more compression, more memory needed during decompression */
+    unsigned chainLog;        /*< fully searched segment : larger == more compression, slower, more memory (useless for fast) */
+    unsigned hashLog;         /*< dispatch table : larger == faster, more memory */
+    unsigned searchLog;       /*< nb of searches : larger == more compression, slower */
+    unsigned minMatch;        /*< match length searched : larger == faster decompression, sometimes less compression */
+    unsigned targetLength;    /*< acceptable match size for optimal parser (only) : larger == more compression, slower */
+    ZSTD_strategy strategy;   /*< see ZSTD_strategy definition above */
 } ZSTD_compressionParameters;
 
 typedef struct {
-    int contentSizeFlag; /**< 1: content size will be in frame header (when known) */
-    int checksumFlag;    /**< 1: generate a 32-bits checksum using XXH64 algorithm at end of frame, for error detection */
-    int noDictIDFlag;    /**< 1: no dictID will be saved into frame header (dictID is only useful for dictionary compression) */
+    int contentSizeFlag; /*< 1: content size will be in frame header (when known) */
+    int checksumFlag;    /*< 1: generate a 32-bits checksum using XXH64 algorithm at end of frame, for error detection */
+    int noDictIDFlag;    /*< 1: no dictID will be saved into frame header (dictID is only useful for dictionary compression) */
 } ZSTD_frameParameters;
 
 typedef struct {
@@ -1184,8 +1184,8 @@ typedef enum {
 } ZSTD_dictContentType_e;
 
 typedef enum {
-    ZSTD_dlm_byCopy = 0,  /**< Copy dictionary content internally */
-    ZSTD_dlm_byRef = 1    /**< Reference dictionary content -- the dictionary buffer must outlive its users. */
+    ZSTD_dlm_byCopy = 0,  /*< Copy dictionary content internally */
+    ZSTD_dlm_byRef = 1    /*< Reference dictionary content -- the dictionary buffer must outlive its users. */
 } ZSTD_dictLoadMethod_e;
 
 typedef enum {
@@ -1247,16 +1247,16 @@ typedef enum {
 } ZSTD_dictAttachPref_e;
 
 typedef enum {
-  ZSTD_lcm_auto = 0,          /**< Automatically determine the compression mode based on the compression level.
+  ZSTD_lcm_auto = 0,          /*< Automatically determine the compression mode based on the compression level.
                                *   Negative compression levels will be uncompressed, and positive compression
                                *   levels will be compressed. */
-  ZSTD_lcm_huffman = 1,       /**< Always attempt Huffman compression. Uncompressed literals will still be
+  ZSTD_lcm_huffman = 1,       /*< Always attempt Huffman compression. Uncompressed literals will still be
                                *   emitted if Huffman compression is not profitable. */
-  ZSTD_lcm_uncompressed = 2   /**< Always emit uncompressed literals. */
+  ZSTD_lcm_uncompressed = 2   /*< Always emit uncompressed literals. */
 } ZSTD_literalCompressionMode_e;
 
 
-/***************************************
+/* *************************************
 *  Frame size functions
 ***************************************/
 
@@ -1391,7 +1391,7 @@ ZSTDLIB_API size_t ZSTD_writeSkippableFrame(void* dst, size_t dstCapacity,
                                             const void* src, size_t srcSize, unsigned magicVariant);
 
 
-/***************************************
+/* *************************************
 *  Memory management
 ***************************************/
 
@@ -1473,10 +1473,10 @@ ZSTDLIB_API size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e
  *  Limitation 3 : static dctx is incompatible with legacy support.
  */
 ZSTDLIB_API ZSTD_CCtx*    ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);
-ZSTDLIB_API ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize);    /**< same as ZSTD_initStaticCCtx() */
+ZSTDLIB_API ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize);    /*< same as ZSTD_initStaticCCtx() */
 
 ZSTDLIB_API ZSTD_DCtx*    ZSTD_initStaticDCtx(void* workspace, size_t workspaceSize);
-ZSTDLIB_API ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize);    /**< same as ZSTD_initStaticDCtx() */
+ZSTDLIB_API ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize);    /*< same as ZSTD_initStaticDCtx() */
 
 ZSTDLIB_API const ZSTD_CDict* ZSTD_initStaticCDict(
                                         void* workspace, size_t workspaceSize,
@@ -1502,7 +1502,7 @@ typedef void  (*ZSTD_freeFunction) (void* opaque, void* address);
 typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;
 static
 __attribute__((__unused__))
-ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL };  /**< this constant defers to stdlib's functions */
+ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL };  /*< this constant defers to stdlib's functions */
 
 ZSTDLIB_API ZSTD_CCtx*    ZSTD_createCCtx_advanced(ZSTD_customMem customMem);
 ZSTDLIB_API ZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem);
@@ -1548,7 +1548,7 @@ ZSTDLIB_API ZSTD_DDict* ZSTD_createDDict_advanced(
     ZSTD_customMem customMem);
 
 
-/***************************************
+/* *************************************
 *  Advanced compression functions
 ***************************************/
 
@@ -1902,7 +1902,7 @@ ZSTDLIB_API size_t ZSTD_compressStream2_simpleArgs (
                             ZSTD_EndDirective endOp);
 
 
-/***************************************
+/* *************************************
 *  Advanced decompression functions
 ***************************************/
 
@@ -2046,7 +2046,7 @@ ZSTDLIB_API size_t ZSTD_decompressStream_simpleArgs (
                       const void* src, size_t srcSize, size_t* srcPos);
 
 
-/********************************************************************
+/* ******************************************************************
 *  Advanced streaming functions
 *  Warning : most of these functions are now redundant with the Advanced API.
 *  Once Advanced API reaches "stable" status,
@@ -2227,7 +2227,7 @@ ZSTDLIB_API size_t ZSTD_initDStream_usingDDict(ZSTD_DStream* zds, const ZSTD_DDi
 ZSTDLIB_API size_t ZSTD_resetDStream(ZSTD_DStream* zds);
 
 
-/*********************************************************************
+/* *******************************************************************
 *  Buffer-less and synchronous inner streaming functions
 *
 *  This is an advanced API, giving full control over buffer management, for users which need direct control over memory.
@@ -2235,7 +2235,7 @@ ZSTDLIB_API size_t ZSTD_resetDStream(ZSTD_DStream* zds);
 *  Prefer normal streaming API for an easier experience.
 ********************************************************************* */
 
-/**
+/*
   Buffer-less streaming compression (synchronous mode)
 
   A ZSTD_CCtx object is required to track streaming operations.
@@ -2269,16 +2269,16 @@ ZSTDLIB_API size_t ZSTD_resetDStream(ZSTD_DStream* zds);
 /*=====   Buffer-less streaming compression functions  =====*/
 ZSTDLIB_API size_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);
 ZSTDLIB_API size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel);
-ZSTDLIB_API size_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize : If srcSize is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN */
-ZSTDLIB_API size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict); /**< note: fails if cdict==NULL */
+ZSTDLIB_API size_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize); /*< pledgedSrcSize : If srcSize is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN */
+ZSTDLIB_API size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict); /*< note: fails if cdict==NULL */
 ZSTDLIB_API size_t ZSTD_compressBegin_usingCDict_advanced(ZSTD_CCtx* const cctx, const ZSTD_CDict* const cdict, ZSTD_frameParameters const fParams, unsigned long long const pledgedSrcSize);   /* compression parameters are already set within cdict. pledgedSrcSize must be correct. If srcSize is not known, use macro ZSTD_CONTENTSIZE_UNKNOWN */
-ZSTDLIB_API size_t ZSTD_copyCCtx(ZSTD_CCtx* cctx, const ZSTD_CCtx* preparedCCtx, unsigned long long pledgedSrcSize); /**<  note: if pledgedSrcSize is not known, use ZSTD_CONTENTSIZE_UNKNOWN */
+ZSTDLIB_API size_t ZSTD_copyCCtx(ZSTD_CCtx* cctx, const ZSTD_CCtx* preparedCCtx, unsigned long long pledgedSrcSize); /*<  note: if pledgedSrcSize is not known, use ZSTD_CONTENTSIZE_UNKNOWN */
 
 ZSTDLIB_API size_t ZSTD_compressContinue(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
 ZSTDLIB_API size_t ZSTD_compressEnd(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
 
 
-/**
+/*
   Buffer-less streaming decompression (synchronous mode)
 
   A ZSTD_DCtx object is required to track streaming operations.
@@ -2368,12 +2368,12 @@ typedef struct {
  * @return : 0, `zfhPtr` is correctly filled,
  *          >0, `srcSize` is too small, value is wanted `srcSize` amount,
  *           or an error code, which can be tested using ZSTD_isError() */
-ZSTDLIB_API size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize);   /**< doesn't consume input */
+ZSTDLIB_API size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize);   /*< doesn't consume input */
 /*! ZSTD_getFrameHeader_advanced() :
  *  same as ZSTD_getFrameHeader(),
  *  with added capability to select a format (like ZSTD_f_zstd1_magicless) */
 ZSTDLIB_API size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize, ZSTD_format_e format);
-ZSTDLIB_API size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize);  /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */
+ZSTDLIB_API size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize);  /*< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */
 
 ZSTDLIB_API size_t ZSTD_decompressBegin(ZSTD_DCtx* dctx);
 ZSTDLIB_API size_t ZSTD_decompressBegin_usingDict(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);
@@ -2391,7 +2391,7 @@ ZSTDLIB_API ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx* dctx);
 
 
 /* ============================ */
-/**       Block level API       */
+/*       Block level API       */
 /* ============================ */
 
 /*!
@@ -2425,7 +2425,7 @@ ZSTDLIB_API ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx* dctx);
 ZSTDLIB_API size_t ZSTD_getBlockSize   (const ZSTD_CCtx* cctx);
 ZSTDLIB_API size_t ZSTD_compressBlock  (ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
 ZSTDLIB_API size_t ZSTD_decompressBlock(ZSTD_DCtx* dctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
-ZSTDLIB_API size_t ZSTD_insertBlock    (ZSTD_DCtx* dctx, const void* blockStart, size_t blockSize);  /**< insert uncompressed block into `dctx` history. Useful for multi-blocks decompression. */
+ZSTDLIB_API size_t ZSTD_insertBlock    (ZSTD_DCtx* dctx, const void* blockStart, size_t blockSize);  /*< insert uncompressed block into `dctx` history. Useful for multi-blocks decompression. */
 
 
 #endif   /* ZSTD_H_ZSTD_STATIC_LINKING_ONLY */
diff --git a/lib/zstd/common/compiler.h b/lib/zstd/common/compiler.h
index 9269b58a9..a8286d8c4 100644
--- a/lib/zstd/common/compiler.h
+++ b/lib/zstd/common/compiler.h
@@ -25,20 +25,20 @@
 #define FORCE_INLINE_ATTR __attribute__((always_inline))
 
 
-/**
+/*
   On MSVC qsort requires that functions passed into it use the __cdecl calling conversion(CC).
   This explictly marks such functions as __cdecl so that the code will still compile
   if a CC other than __cdecl has been made the default.
 */
 #define WIN_CDECL
 
-/**
+/*
  * FORCE_INLINE_TEMPLATE is used to define C "templates", which take constant
  * parameters. They must be inlined for the compiler to eliminate the constant
  * branches.
  */
 #define FORCE_INLINE_TEMPLATE static INLINE_KEYWORD FORCE_INLINE_ATTR
-/**
+/*
  * HINT_INLINE is used to help the compiler generate better code. It is *not*
  * used for "templates", so it can be tweaked based on the compilers
  * performance.
diff --git a/lib/zstd/common/cpu.h b/lib/zstd/common/cpu.h
index 0202d9407..0db7b4240 100644
--- a/lib/zstd/common/cpu.h
+++ b/lib/zstd/common/cpu.h
@@ -11,7 +11,7 @@
 #ifndef ZSTD_COMMON_CPU_H
 #define ZSTD_COMMON_CPU_H
 
-/**
+/*
  * Implementation taken from folly/CpuId.h
  * https://github.com/facebook/folly/blob/master/folly/CpuId.h
  */
diff --git a/lib/zstd/common/fse.h b/lib/zstd/common/fse.h
index 9e3f09ed1..0bb174c2c 100644
--- a/lib/zstd/common/fse.h
+++ b/lib/zstd/common/fse.h
@@ -47,7 +47,7 @@
 #define FSE_VERSION_STRING FSE_EXPAND_AND_QUOTE(FSE_LIB_VERSION)
 
 #define FSE_VERSION_NUMBER  (FSE_VERSION_MAJOR *100*100 + FSE_VERSION_MINOR *100 + FSE_VERSION_RELEASE)
-FSE_PUBLIC_API unsigned FSE_versionNumber(void);   /**< library version number; to be used when checking dll version */
+FSE_PUBLIC_API unsigned FSE_versionNumber(void);   /*< library version number; to be used when checking dll version */
 
 
 /*-****************************************
@@ -315,7 +315,7 @@ If there is an error, the function will return an error code, which can be teste
  ***************************************** */
 
 unsigned FSE_optimalTableLog_internal(unsigned maxTableLog, size_t srcSize, unsigned maxSymbolValue, unsigned minus);
-/**< same as FSE_optimalTableLog(), which used `minus==2` */
+/*< same as FSE_optimalTableLog(), which used `minus==2` */
 
 /* FSE_compress_wksp() :
  * Same as FSE_compress2(), but using an externally allocated scratch buffer (`workSpace`).
@@ -325,10 +325,10 @@ unsigned FSE_optimalTableLog_internal(unsigned maxTableLog, size_t srcSize, unsi
 size_t FSE_compress_wksp (void* dst, size_t dstSize, const void* src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void* workSpace, size_t wkspSize);
 
 size_t FSE_buildCTable_raw (FSE_CTable* ct, unsigned nbBits);
-/**< build a fake FSE_CTable, designed for a flat distribution, where each symbol uses nbBits */
+/*< build a fake FSE_CTable, designed for a flat distribution, where each symbol uses nbBits */
 
 size_t FSE_buildCTable_rle (FSE_CTable* ct, unsigned char symbolValue);
-/**< build a fake FSE_CTable, designed to compress always the same symbolValue */
+/*< build a fake FSE_CTable, designed to compress always the same symbolValue */
 
 /* FSE_buildCTable_wksp() :
  * Same as FSE_buildCTable(), but using an externally allocated scratch buffer (`workSpace`).
@@ -341,26 +341,26 @@ size_t FSE_buildCTable_wksp(FSE_CTable* ct, const short* normalizedCounter, unsi
 #define FSE_BUILD_DTABLE_WKSP_SIZE(maxTableLog, maxSymbolValue) (sizeof(short) * (maxSymbolValue + 1) + (1ULL << maxTableLog) + 8)
 #define FSE_BUILD_DTABLE_WKSP_SIZE_U32(maxTableLog, maxSymbolValue) ((FSE_BUILD_DTABLE_WKSP_SIZE(maxTableLog, maxSymbolValue) + sizeof(unsigned) - 1) / sizeof(unsigned))
 FSE_PUBLIC_API size_t FSE_buildDTable_wksp(FSE_DTable* dt, const short* normalizedCounter, unsigned maxSymbolValue, unsigned tableLog, void* workSpace, size_t wkspSize);
-/**< Same as FSE_buildDTable(), using an externally allocated `workspace` produced with `FSE_BUILD_DTABLE_WKSP_SIZE_U32(maxSymbolValue)` */
+/*< Same as FSE_buildDTable(), using an externally allocated `workspace` produced with `FSE_BUILD_DTABLE_WKSP_SIZE_U32(maxSymbolValue)` */
 
 size_t FSE_buildDTable_raw (FSE_DTable* dt, unsigned nbBits);
-/**< build a fake FSE_DTable, designed to read a flat distribution where each symbol uses nbBits */
+/*< build a fake FSE_DTable, designed to read a flat distribution where each symbol uses nbBits */
 
 size_t FSE_buildDTable_rle (FSE_DTable* dt, unsigned char symbolValue);
-/**< build a fake FSE_DTable, designed to always generate the same symbolValue */
+/*< build a fake FSE_DTable, designed to always generate the same symbolValue */
 
 #define FSE_DECOMPRESS_WKSP_SIZE_U32(maxTableLog, maxSymbolValue) (FSE_DTABLE_SIZE_U32(maxTableLog) + FSE_BUILD_DTABLE_WKSP_SIZE_U32(maxTableLog, maxSymbolValue) + (FSE_MAX_SYMBOL_VALUE + 1) / 2 + 1)
 #define FSE_DECOMPRESS_WKSP_SIZE(maxTableLog, maxSymbolValue) (FSE_DECOMPRESS_WKSP_SIZE_U32(maxTableLog, maxSymbolValue) * sizeof(unsigned))
 size_t FSE_decompress_wksp(void* dst, size_t dstCapacity, const void* cSrc, size_t cSrcSize, unsigned maxLog, void* workSpace, size_t wkspSize);
-/**< same as FSE_decompress(), using an externally allocated `workSpace` produced with `FSE_DECOMPRESS_WKSP_SIZE_U32(maxLog, maxSymbolValue)` */
+/*< same as FSE_decompress(), using an externally allocated `workSpace` produced with `FSE_DECOMPRESS_WKSP_SIZE_U32(maxLog, maxSymbolValue)` */
 
 size_t FSE_decompress_wksp_bmi2(void* dst, size_t dstCapacity, const void* cSrc, size_t cSrcSize, unsigned maxLog, void* workSpace, size_t wkspSize, int bmi2);
-/**< Same as FSE_decompress_wksp() but with dynamic BMI2 support. Pass 1 if your CPU supports BMI2 or 0 if it doesn't. */
+/*< Same as FSE_decompress_wksp() but with dynamic BMI2 support. Pass 1 if your CPU supports BMI2 or 0 if it doesn't. */
 
 typedef enum {
-   FSE_repeat_none,  /**< Cannot use the previous table */
-   FSE_repeat_check, /**< Can use the previous table but it must be checked */
-   FSE_repeat_valid  /**< Can use the previous table and it is assumed to be valid */
+   FSE_repeat_none,  /*< Cannot use the previous table */
+   FSE_repeat_check, /*< Can use the previous table but it must be checked */
+   FSE_repeat_valid  /*< Can use the previous table and it is assumed to be valid */
  } FSE_repeat;
 
 /* *****************************************
@@ -383,7 +383,7 @@ static void FSE_encodeSymbol(BIT_CStream_t* bitC, FSE_CState_t* CStatePtr, unsig
 
 static void FSE_flushCState(BIT_CStream_t* bitC, const FSE_CState_t* CStatePtr);
 
-/**<
+/*<
 These functions are inner components of FSE_compress_usingCTable().
 They allow the creation of custom streams, mixing multiple tables and bit sources.
 
@@ -442,7 +442,7 @@ static unsigned char FSE_decodeSymbol(FSE_DState_t* DStatePtr, BIT_DStream_t* bi
 
 static unsigned FSE_endOfDState(const FSE_DState_t* DStatePtr);
 
-/**<
+/*<
 Let's now decompose FSE_decompress_usingDTable() into its unitary components.
 You will decode FSE-encoded symbols from the bitStream,
 and also any other bitFields you put in, **in reverse order**.
diff --git a/lib/zstd/common/huf.h b/lib/zstd/common/huf.h
index 49939016c..88c558664 100644
--- a/lib/zstd/common/huf.h
+++ b/lib/zstd/common/huf.h
@@ -39,7 +39,7 @@
 /* ***  simple functions  *** */
 /* ========================== */
 
-/** HUF_compress() :
+/* HUF_compress() :
  *  Compress content from buffer 'src', of size 'srcSize', into buffer 'dst'.
  * 'dst' buffer must be already allocated.
  *  Compression runs faster if `dstCapacity` >= HUF_compressBound(srcSize).
@@ -51,7 +51,7 @@
 HUF_PUBLIC_API size_t HUF_compress(void* dst, size_t dstCapacity,
                              const void* src, size_t srcSize);
 
-/** HUF_decompress() :
+/* HUF_decompress() :
  *  Decompress HUF data from buffer 'cSrc', of size 'cSrcSize',
  *  into already allocated buffer 'dst', of minimum size 'dstSize'.
  * `originalSize` : **must** be the ***exact*** size of original (uncompressed) data.
@@ -66,17 +66,17 @@ HUF_PUBLIC_API size_t HUF_decompress(void* dst,  size_t originalSize,
 
 
 /* ***   Tool functions *** */
-#define HUF_BLOCKSIZE_MAX (128 * 1024)                  /**< maximum input size for a single block compressed with HUF_compress */
-HUF_PUBLIC_API size_t HUF_compressBound(size_t size);   /**< maximum compressed size (worst case) */
+#define HUF_BLOCKSIZE_MAX (128 * 1024)                  /*< maximum input size for a single block compressed with HUF_compress */
+HUF_PUBLIC_API size_t HUF_compressBound(size_t size);   /*< maximum compressed size (worst case) */
 
 /* Error Management */
-HUF_PUBLIC_API unsigned    HUF_isError(size_t code);       /**< tells if a return value is an error code */
-HUF_PUBLIC_API const char* HUF_getErrorName(size_t code);  /**< provides error code string (useful for debugging) */
+HUF_PUBLIC_API unsigned    HUF_isError(size_t code);       /*< tells if a return value is an error code */
+HUF_PUBLIC_API const char* HUF_getErrorName(size_t code);  /*< provides error code string (useful for debugging) */
 
 
 /* ***   Advanced function   *** */
 
-/** HUF_compress2() :
+/* HUF_compress2() :
  *  Same as HUF_compress(), but offers control over `maxSymbolValue` and `tableLog`.
  * `maxSymbolValue` must be <= HUF_SYMBOLVALUE_MAX .
  * `tableLog` must be `<= HUF_TABLELOG_MAX` . */
@@ -84,7 +84,7 @@ HUF_PUBLIC_API size_t HUF_compress2 (void* dst, size_t dstCapacity,
                                const void* src, size_t srcSize,
                                unsigned maxSymbolValue, unsigned tableLog);
 
-/** HUF_compress4X_wksp() :
+/* HUF_compress4X_wksp() :
  *  Same as HUF_compress2(), but uses externally allocated `workSpace`.
  * `workspace` must have minimum alignment of 4, and be at least as large as HUF_WORKSPACE_SIZE */
 #define HUF_WORKSPACE_SIZE ((6 << 10) + 256)
@@ -155,19 +155,19 @@ typedef U32 HUF_DTable;
 /* ****************************************
 *  Advanced decompression functions
 ******************************************/
-size_t HUF_decompress4X1 (void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< single-symbol decoder */
+size_t HUF_decompress4X1 (void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< single-symbol decoder */
 #ifndef HUF_FORCE_DECOMPRESS_X1
-size_t HUF_decompress4X2 (void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< double-symbols decoder */
+size_t HUF_decompress4X2 (void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< double-symbols decoder */
 #endif
 
-size_t HUF_decompress4X_DCtx (HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< decodes RLE and uncompressed */
-size_t HUF_decompress4X_hufOnly(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize); /**< considers RLE and uncompressed as errors */
-size_t HUF_decompress4X_hufOnly_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize); /**< considers RLE and uncompressed as errors */
-size_t HUF_decompress4X1_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< single-symbol decoder */
-size_t HUF_decompress4X1_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /**< single-symbol decoder */
+size_t HUF_decompress4X_DCtx (HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< decodes RLE and uncompressed */
+size_t HUF_decompress4X_hufOnly(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize); /*< considers RLE and uncompressed as errors */
+size_t HUF_decompress4X_hufOnly_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize); /*< considers RLE and uncompressed as errors */
+size_t HUF_decompress4X1_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< single-symbol decoder */
+size_t HUF_decompress4X1_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /*< single-symbol decoder */
 #ifndef HUF_FORCE_DECOMPRESS_X1
-size_t HUF_decompress4X2_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< double-symbols decoder */
-size_t HUF_decompress4X2_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /**< double-symbols decoder */
+size_t HUF_decompress4X2_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< double-symbols decoder */
+size_t HUF_decompress4X2_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /*< double-symbols decoder */
 #endif
 
 
@@ -195,11 +195,11 @@ size_t HUF_estimateCompressedSize(const HUF_CElt* CTable, const unsigned* count,
 int HUF_validateCTable(const HUF_CElt* CTable, const unsigned* count, unsigned maxSymbolValue);
 
 typedef enum {
-   HUF_repeat_none,  /**< Cannot use the previous table */
-   HUF_repeat_check, /**< Can use the previous table but it must be checked. Note : The previous table must have been constructed by HUF_compress{1, 4}X_repeat */
-   HUF_repeat_valid  /**< Can use the previous table and it is assumed to be valid */
+   HUF_repeat_none,  /*< Cannot use the previous table */
+   HUF_repeat_check, /*< Can use the previous table but it must be checked. Note : The previous table must have been constructed by HUF_compress{1, 4}X_repeat */
+   HUF_repeat_valid  /*< Can use the previous table and it is assumed to be valid */
  } HUF_repeat;
-/** HUF_compress4X_repeat() :
+/* HUF_compress4X_repeat() :
  *  Same as HUF_compress4X_wksp(), but considers using hufTable if *repeat != HUF_repeat_none.
  *  If it uses hufTable it does not modify hufTable or repeat.
  *  If it doesn't, it sets *repeat = HUF_repeat_none, and it sets hufTable to the table used.
@@ -207,10 +207,10 @@ typedef enum {
 size_t HUF_compress4X_repeat(void* dst, size_t dstSize,
                        const void* src, size_t srcSize,
                        unsigned maxSymbolValue, unsigned tableLog,
-                       void* workSpace, size_t wkspSize,    /**< `workSpace` must be aligned on 4-bytes boundaries, `wkspSize` must be >= HUF_WORKSPACE_SIZE */
+                       void* workSpace, size_t wkspSize,    /*< `workSpace` must be aligned on 4-bytes boundaries, `wkspSize` must be >= HUF_WORKSPACE_SIZE */
                        HUF_CElt* hufTable, HUF_repeat* repeat, int preferRepeat, int bmi2);
 
-/** HUF_buildCTable_wksp() :
+/* HUF_buildCTable_wksp() :
  *  Same as HUF_buildCTable(), but using externally allocated scratch buffer.
  * `workSpace` must be aligned on 4-bytes boundaries, and its size must be >= HUF_CTABLE_WORKSPACE_SIZE.
  */
@@ -242,11 +242,11 @@ size_t HUF_readStats_wksp(BYTE* huffWeight, size_t hwSize,
                           void* workspace, size_t wkspSize,
                           int bmi2);
 
-/** HUF_readCTable() :
+/* HUF_readCTable() :
  *  Loading a CTable saved with HUF_writeCTable() */
 size_t HUF_readCTable (HUF_CElt* CTable, unsigned* maxSymbolValuePtr, const void* src, size_t srcSize, unsigned *hasZeroWeights);
 
-/** HUF_getNbBits() :
+/* HUF_getNbBits() :
  *  Read nbBits from CTable symbolTable, for symbol `symbolValue` presumed <= HUF_SYMBOLVALUE_MAX
  *  Note 1 : is not inlined, as HUF_CElt definition is private
  *  Note 2 : const void* used, so that it can provide a statically allocated table as argument (which uses type U32) */
@@ -259,14 +259,14 @@ U32 HUF_getNbBits(const void* symbolTable, U32 symbolValue);
  * 3. decode 1 or 4 segments in parallel using HUF_decompress?X?_usingDTable()
  */
 
-/** HUF_selectDecoder() :
+/* HUF_selectDecoder() :
  *  Tells which decoder is likely to decode faster,
  *  based on a set of pre-computed metrics.
  * @return : 0==HUF_decompress4X1, 1==HUF_decompress4X2 .
  *  Assumption : 0 < dstSize <= 128 KB */
 U32 HUF_selectDecoder (size_t dstSize, size_t cSrcSize);
 
-/**
+/*
  *  The minimum workspace size for the `workSpace` used in
  *  HUF_readDTableX1_wksp() and HUF_readDTableX2_wksp().
  *
@@ -302,9 +302,9 @@ size_t HUF_decompress4X2_usingDTable(void* dst, size_t maxDstSize, const void* c
 /* ====================== */
 
 size_t HUF_compress1X (void* dst, size_t dstSize, const void* src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog);
-size_t HUF_compress1X_wksp (void* dst, size_t dstSize, const void* src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void* workSpace, size_t wkspSize);  /**< `workSpace` must be a table of at least HUF_WORKSPACE_SIZE_U32 unsigned */
+size_t HUF_compress1X_wksp (void* dst, size_t dstSize, const void* src, size_t srcSize, unsigned maxSymbolValue, unsigned tableLog, void* workSpace, size_t wkspSize);  /*< `workSpace` must be a table of at least HUF_WORKSPACE_SIZE_U32 unsigned */
 size_t HUF_compress1X_usingCTable(void* dst, size_t dstSize, const void* src, size_t srcSize, const HUF_CElt* CTable);
-/** HUF_compress1X_repeat() :
+/* HUF_compress1X_repeat() :
  *  Same as HUF_compress1X_wksp(), but considers using hufTable if *repeat != HUF_repeat_none.
  *  If it uses hufTable it does not modify hufTable or repeat.
  *  If it doesn't, it sets *repeat = HUF_repeat_none, and it sets hufTable to the table used.
@@ -312,7 +312,7 @@ size_t HUF_compress1X_usingCTable(void* dst, size_t dstSize, const void* src, si
 size_t HUF_compress1X_repeat(void* dst, size_t dstSize,
                        const void* src, size_t srcSize,
                        unsigned maxSymbolValue, unsigned tableLog,
-                       void* workSpace, size_t wkspSize,   /**< `workSpace` must be aligned on 4-bytes boundaries, `wkspSize` must be >= HUF_WORKSPACE_SIZE */
+                       void* workSpace, size_t wkspSize,   /*< `workSpace` must be aligned on 4-bytes boundaries, `wkspSize` must be >= HUF_WORKSPACE_SIZE */
                        HUF_CElt* hufTable, HUF_repeat* repeat, int preferRepeat, int bmi2);
 
 size_t HUF_decompress1X1 (void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /* single-symbol decoder */
@@ -323,15 +323,15 @@ size_t HUF_decompress1X2 (void* dst, size_t dstSize, const void* cSrc, size_t cS
 size_t HUF_decompress1X_DCtx (HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);
 size_t HUF_decompress1X_DCtx_wksp (HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);
 #ifndef HUF_FORCE_DECOMPRESS_X2
-size_t HUF_decompress1X1_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< single-symbol decoder */
-size_t HUF_decompress1X1_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /**< single-symbol decoder */
+size_t HUF_decompress1X1_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< single-symbol decoder */
+size_t HUF_decompress1X1_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /*< single-symbol decoder */
 #endif
 #ifndef HUF_FORCE_DECOMPRESS_X1
-size_t HUF_decompress1X2_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /**< double-symbols decoder */
-size_t HUF_decompress1X2_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /**< double-symbols decoder */
+size_t HUF_decompress1X2_DCtx(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize);   /*< double-symbols decoder */
+size_t HUF_decompress1X2_DCtx_wksp(HUF_DTable* dctx, void* dst, size_t dstSize, const void* cSrc, size_t cSrcSize, void* workSpace, size_t wkspSize);   /*< double-symbols decoder */
 #endif
 
-size_t HUF_decompress1X_usingDTable(void* dst, size_t maxDstSize, const void* cSrc, size_t cSrcSize, const HUF_DTable* DTable);   /**< automatic selection of sing or double symbol decoder, based on DTable */
+size_t HUF_decompress1X_usingDTable(void* dst, size_t maxDstSize, const void* cSrc, size_t cSrcSize, const HUF_DTable* DTable);   /*< automatic selection of sing or double symbol decoder, based on DTable */
 #ifndef HUF_FORCE_DECOMPRESS_X2
 size_t HUF_decompress1X1_usingDTable(void* dst, size_t maxDstSize, const void* cSrc, size_t cSrcSize, const HUF_DTable* DTable);
 #endif
diff --git a/lib/zstd/common/zstd_internal.h b/lib/zstd/common/zstd_internal.h
index 1f939cbe0..fc6f3a9b4 100644
--- a/lib/zstd/common/zstd_internal.h
+++ b/lib/zstd/common/zstd_internal.h
@@ -48,7 +48,7 @@
 #define MIN(a,b) ((a)<(b) ? (a) : (b))
 #define MAX(a,b) ((a)>(b) ? (a) : (b))
 
-/**
+/*
  * Ignore: this is an internal helper.
  *
  * This is a helper function to help force C99-correctness during compilation.
@@ -62,7 +62,7 @@ void _force_has_format_string(const char *format, ...) {
   (void)format;
 }
 
-/**
+/*
  * Ignore: this is an internal helper.
  *
  * We want to force this function invocation to be syntactically correct, but
@@ -73,7 +73,7 @@ void _force_has_format_string(const char *format, ...) {
     _force_has_format_string(__VA_ARGS__); \
   }
 
-/**
+/*
  * Return the specified error if the condition evaluates to true.
  *
  * In debug modes, prints additional information.
@@ -90,7 +90,7 @@ void _force_has_format_string(const char *format, ...) {
     return ERROR(err); \
   }
 
-/**
+/*
  * Unconditionally return the specified error.
  *
  * In debug modes, prints additional information.
@@ -105,7 +105,7 @@ void _force_has_format_string(const char *format, ...) {
     return ERROR(err); \
   } while(0);
 
-/**
+/*
  * If the provided expression evaluates to an error code, returns that error code.
  *
  * In debug modes, prints additional information.
@@ -360,7 +360,7 @@ typedef struct {
     U32 matchLength;
 } ZSTD_sequenceLength;
 
-/**
+/*
  * Returns the ZSTD_sequenceLength for the given sequences. It handles the decoding of long sequences
  * indicated by longLengthPos and longLengthID, and adds MINMATCH back to matchLength.
  */
@@ -380,7 +380,7 @@ MEM_STATIC ZSTD_sequenceLength ZSTD_getSequenceLength(seqStore_t const* seqStore
     return seqLen;
 }
 
-/**
+/*
  * Contains the compressed frame size and an upper-bound for the decompressed frame size.
  * Note: before using `compressedSize`, check for errors using ZSTD_isError().
  *       similarly, before using `decompressedBound`, check for errors using:
diff --git a/lib/zstd/compress/hist.h b/lib/zstd/compress/hist.h
index 228ed48a7..fc1830abc 100644
--- a/lib/zstd/compress/hist.h
+++ b/lib/zstd/compress/hist.h
@@ -30,14 +30,14 @@
 size_t HIST_count(unsigned* count, unsigned* maxSymbolValuePtr,
                   const void* src, size_t srcSize);
 
-unsigned HIST_isError(size_t code);  /**< tells if a return value is an error code */
+unsigned HIST_isError(size_t code);  /*< tells if a return value is an error code */
 
 
 /* --- advanced histogram functions --- */
 
 #define HIST_WKSP_SIZE_U32 1024
 #define HIST_WKSP_SIZE    (HIST_WKSP_SIZE_U32 * sizeof(unsigned))
-/** HIST_count_wksp() :
+/* HIST_count_wksp() :
  *  Same as HIST_count(), but using an externally provided scratch buffer.
  *  Benefit is this function will use very little stack space.
  * `workSpace` is a writable buffer which must be 4-bytes aligned,
@@ -47,14 +47,14 @@ size_t HIST_count_wksp(unsigned* count, unsigned* maxSymbolValuePtr,
                        const void* src, size_t srcSize,
                        void* workSpace, size_t workSpaceSize);
 
-/** HIST_countFast() :
+/* HIST_countFast() :
  *  same as HIST_count(), but blindly trusts that all byte values within src are <= *maxSymbolValuePtr.
  *  This function is unsafe, and will segfault if any value within `src` is `> *maxSymbolValuePtr`
  */
 size_t HIST_countFast(unsigned* count, unsigned* maxSymbolValuePtr,
                       const void* src, size_t srcSize);
 
-/** HIST_countFast_wksp() :
+/* HIST_countFast_wksp() :
  *  Same as HIST_countFast(), but using an externally provided scratch buffer.
  * `workSpace` is a writable buffer which must be 4-bytes aligned,
  * `workSpaceSize` must be >= HIST_WKSP_SIZE
diff --git a/lib/zstd/compress/huf_compress.c b/lib/zstd/compress/huf_compress.c
index 4acae45a4..122e81264 100644
--- a/lib/zstd/compress/huf_compress.c
+++ b/lib/zstd/compress/huf_compress.c
@@ -221,7 +221,7 @@ typedef struct nodeElt_s {
     BYTE nbBits;
 } nodeElt;
 
-/**
+/*
  * HUF_setMaxHeight():
  * Enforces maxNbBits on the Huffman tree described in huffNode.
  *
@@ -377,7 +377,7 @@ typedef struct {
   rankPos rankPosition[RANK_POSITION_TABLE_SIZE];
 } HUF_buildCTable_wksp_tables;
 
-/**
+/*
  * HUF_sort():
  * Sorts the symbols [0, maxSymbolValue] by count[symbol] in decreasing order.
  *
@@ -426,7 +426,7 @@ static void HUF_sort(nodeElt* huffNode, const unsigned* count, U32 maxSymbolValu
 }
 
 
-/** HUF_buildCTable_wksp() :
+/* HUF_buildCTable_wksp() :
  *  Same as HUF_buildCTable(), but using externally allocated scratch buffer.
  *  `workSpace` must be aligned on 4-bytes boundaries, and be at least as large as sizeof(HUF_buildCTable_wksp_tables).
  */
@@ -475,7 +475,7 @@ static int HUF_buildTree(nodeElt* huffNode, U32 maxSymbolValue)
     return nonNullRank;
 }
 
-/**
+/*
  * HUF_buildCTableFromTree():
  * Build the CTable given the Huffman tree in huffNode.
  *
diff --git a/lib/zstd/compress/zstd_compress.c b/lib/zstd/compress/zstd_compress.c
index 78aa14c50..f5b37ad65 100644
--- a/lib/zstd/compress/zstd_compress.c
+++ b/lib/zstd/compress/zstd_compress.c
@@ -124,7 +124,7 @@ ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize)
     return cctx;
 }
 
-/**
+/*
  * Clears and frees all of the dictionaries in the CCtx.
  */
 static void ZSTD_clearAllDicts(ZSTD_CCtx* cctx)
@@ -261,7 +261,7 @@ size_t ZSTD_CCtxParams_init(ZSTD_CCtx_params* cctxParams, int compressionLevel)
 
 #define ZSTD_NO_CLEVEL 0
 
-/**
+/*
  * Initializes the cctxParams from params and compressionLevel.
  * @param compressionLevel If params are derived from a compression level then that compression level, otherwise ZSTD_NO_CLEVEL.
  */
@@ -285,7 +285,7 @@ size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_paramete
     return 0;
 }
 
-/**
+/*
  * Sets cctxParams' cParams and fParams from params, but otherwise leaves them alone.
  * @param param Validated zstd parameters.
  */
@@ -868,7 +868,7 @@ size_t ZSTD_CCtxParams_getParameter(
     return 0;
 }
 
-/** ZSTD_CCtx_setParametersUsingCCtxParams() :
+/* ZSTD_CCtx_setParametersUsingCCtxParams() :
  *  just applies `params` into `cctx`
  *  no action is performed, parameters are merely stored.
  *  If ZSTDMT is enabled, parameters are pushed to cctx->mtctx.
@@ -906,7 +906,7 @@ static int ZSTD_dedicatedDictSearch_isSupported(
 static void ZSTD_dedicatedDictSearch_revertCParams(
         ZSTD_compressionParameters* cParams);
 
-/**
+/*
  * Initializes the local dict using the requested parameters.
  * NOTE: This does not use the pledged src size, because it may be used for more
  * than one compression.
@@ -1040,7 +1040,7 @@ size_t ZSTD_CCtx_reset(ZSTD_CCtx* cctx, ZSTD_ResetDirective reset)
 }
 
 
-/** ZSTD_checkCParams() :
+/* ZSTD_checkCParams() :
     control CParam values remain within authorized range.
     @return : 0, or an error code if one value is beyond authorized range */
 size_t ZSTD_checkCParams(ZSTD_compressionParameters cParams)
@@ -1055,7 +1055,7 @@ size_t ZSTD_checkCParams(ZSTD_compressionParameters cParams)
     return 0;
 }
 
-/** ZSTD_clampCParams() :
+/* ZSTD_clampCParams() :
  *  make CParam values within valid range.
  *  @return : valid CParams */
 static ZSTD_compressionParameters
@@ -1077,7 +1077,7 @@ ZSTD_clampCParams(ZSTD_compressionParameters cParams)
     return cParams;
 }
 
-/** ZSTD_cycleLog() :
+/* ZSTD_cycleLog() :
  *  condition for correct operation : hashLog > 1 */
 U32 ZSTD_cycleLog(U32 hashLog, ZSTD_strategy strat)
 {
@@ -1085,7 +1085,7 @@ U32 ZSTD_cycleLog(U32 hashLog, ZSTD_strategy strat)
     return hashLog - btScale;
 }
 
-/** ZSTD_dictAndWindowLog() :
+/* ZSTD_dictAndWindowLog() :
  * Returns an adjusted window log that is large enough to fit the source and the dictionary.
  * The zstd format says that the entire dictionary is valid if one byte of the dictionary
  * is within the window. So the hashLog and chainLog should be large enough to reference both
@@ -1119,7 +1119,7 @@ static U32 ZSTD_dictAndWindowLog(U32 windowLog, U64 srcSize, U64 dictSize)
     }
 }
 
-/** ZSTD_adjustCParams_internal() :
+/* ZSTD_adjustCParams_internal() :
  *  optimize `cPar` for a specified input (`srcSize` and `dictSize`).
  *  mostly downsize to reduce memory consumption and initialization latency.
  * `srcSize` can be ZSTD_CONTENTSIZE_UNKNOWN when not known.
@@ -1453,7 +1453,7 @@ static void ZSTD_invalidateMatchState(ZSTD_matchState_t* ms)
     ms->dictMatchState = NULL;
 }
 
-/**
+/*
  * Controls, for this matchState reset, whether the tables need to be cleared /
  * prepared for the coming compression (ZSTDcrp_makeClean), or whether the
  * tables can be left unclean (ZSTDcrp_leaveDirty), because we know that a
@@ -1465,7 +1465,7 @@ typedef enum {
     ZSTDcrp_leaveDirty
 } ZSTD_compResetPolicy_e;
 
-/**
+/*
  * Controls, for this matchState reset, whether indexing can continue where it
  * left off (ZSTDirp_continue), or whether it needs to be restarted from zero
  * (ZSTDirp_reset).
@@ -3264,7 +3264,7 @@ static size_t ZSTD_loadZstdDictionary(ZSTD_compressedBlockState_t* bs,
     return dictID;
 }
 
-/** ZSTD_compress_insertDictionary() :
+/* ZSTD_compress_insertDictionary() :
 *   @return : dictID, or an error code */
 static size_t
 ZSTD_compress_insertDictionary(ZSTD_compressedBlockState_t* bs,
@@ -4082,7 +4082,7 @@ static size_t ZSTD_nextInputSizeHint(const ZSTD_CCtx* cctx)
     return hintInSize;
 }
 
-/** ZSTD_compressStream_generic():
+/* ZSTD_compressStream_generic():
  *  internal function for all *compressStream*() variants
  *  non-static, because can be called from zstdmt_compress.c
  * @return : hint size for next input */
@@ -4999,7 +4999,7 @@ static int ZSTD_dedicatedDictSearch_isSupported(
         && (cParams->chainLog <= 24);
 }
 
-/**
+/*
  * Reverses the adjustment applied to cparams when enabling dedicated dict
  * search. This is used to recover the params set to be used in the working
  * context. (Otherwise, those tables would also grow.)
diff --git a/lib/zstd/compress/zstd_compress_internal.h b/lib/zstd/compress/zstd_compress_internal.h
index b56c48232..0a3b81663 100644
--- a/lib/zstd/compress/zstd_compress_internal.h
+++ b/lib/zstd/compress/zstd_compress_internal.h
@@ -256,7 +256,7 @@ struct ZSTD_CCtx_params_s {
 #define COMPRESS_SEQUENCES_WORKSPACE_SIZE (sizeof(unsigned) * (MaxSeq + 2))
 #define ENTROPY_WORKSPACE_SIZE (HUF_WORKSPACE_SIZE + COMPRESS_SEQUENCES_WORKSPACE_SIZE)
 
-/**
+/*
  * Indicates whether this compression proceeds directly from user-provided
  * source buffer to user-provided destination buffer (ZSTDb_not_buffered), or
  * whether the context needs to buffer the input/output (ZSTDb_buffered).
@@ -633,7 +633,7 @@ MEM_STATIC size_t ZSTD_count(const BYTE* pIn, const BYTE* pMatch, const BYTE* co
     return (size_t)(pIn - pStart);
 }
 
-/** ZSTD_count_2segments() :
+/* ZSTD_count_2segments() :
  *  can count match length with `ip` & `match` in 2 different segments.
  *  convention : on reaching mEnd, match count continue starting from iStart
  */
@@ -694,7 +694,7 @@ size_t ZSTD_hashPtr(const void* p, U32 hBits, U32 mls)
     }
 }
 
-/** ZSTD_ipow() :
+/* ZSTD_ipow() :
  * Return base^exponent.
  */
 static U64 ZSTD_ipow(U64 base, U64 exponent)
@@ -710,7 +710,7 @@ static U64 ZSTD_ipow(U64 base, U64 exponent)
 
 #define ZSTD_ROLL_HASH_CHAR_OFFSET 10
 
-/** ZSTD_rollingHash_append() :
+/* ZSTD_rollingHash_append() :
  * Add the buffer to the hash value.
  */
 static U64 ZSTD_rollingHash_append(U64 hash, void const* buf, size_t size)
@@ -724,7 +724,7 @@ static U64 ZSTD_rollingHash_append(U64 hash, void const* buf, size_t size)
     return hash;
 }
 
-/** ZSTD_rollingHash_compute() :
+/* ZSTD_rollingHash_compute() :
  * Compute the rolling hash value of the buffer.
  */
 MEM_STATIC U64 ZSTD_rollingHash_compute(void const* buf, size_t size)
@@ -732,7 +732,7 @@ MEM_STATIC U64 ZSTD_rollingHash_compute(void const* buf, size_t size)
     return ZSTD_rollingHash_append(0, buf, size);
 }
 
-/** ZSTD_rollingHash_primePower() :
+/* ZSTD_rollingHash_primePower() :
  * Compute the primePower to be passed to ZSTD_rollingHash_rotate() for a hash
  * over a window of length bytes.
  */
@@ -741,7 +741,7 @@ MEM_STATIC U64 ZSTD_rollingHash_primePower(U32 length)
     return ZSTD_ipow(prime8bytes, length - 1);
 }
 
-/** ZSTD_rollingHash_rotate() :
+/* ZSTD_rollingHash_rotate() :
  * Rotate the rolling hash by one byte.
  */
 MEM_STATIC U64 ZSTD_rollingHash_rotate(U64 hash, BYTE toRemove, BYTE toAdd, U64 primePower)
@@ -765,7 +765,7 @@ MEM_STATIC U64 ZSTD_rollingHash_rotate(U64 hash, BYTE toRemove, BYTE toAdd, U64
     ( ((U32)-1)                  /* Maximum ending current index */            \
     - ZSTD_CURRENT_MAX)          /* Maximum beginning lowLimit */
 
-/**
+/*
  * ZSTD_window_clear():
  * Clears the window containing the history by simply setting it to empty.
  */
@@ -778,7 +778,7 @@ MEM_STATIC void ZSTD_window_clear(ZSTD_window_t* window)
     window->dictLimit = end;
 }
 
-/**
+/*
  * ZSTD_window_hasExtDict():
  * Returns non-zero if the window has a non-empty extDict.
  */
@@ -787,7 +787,7 @@ MEM_STATIC U32 ZSTD_window_hasExtDict(ZSTD_window_t const window)
     return window.lowLimit < window.dictLimit;
 }
 
-/**
+/*
  * ZSTD_matchState_dictMode():
  * Inspects the provided matchState and figures out what dictMode should be
  * passed to the compressor.
@@ -801,7 +801,7 @@ MEM_STATIC ZSTD_dictMode_e ZSTD_matchState_dictMode(const ZSTD_matchState_t *ms)
             ZSTD_noDict;
 }
 
-/**
+/*
  * ZSTD_window_needOverflowCorrection():
  * Returns non-zero if the indices are getting too large and need overflow
  * protection.
@@ -813,7 +813,7 @@ MEM_STATIC U32 ZSTD_window_needOverflowCorrection(ZSTD_window_t const window,
     return curr > ZSTD_CURRENT_MAX;
 }
 
-/**
+/*
  * ZSTD_window_correctOverflow():
  * Reduces the indices to protect from index overflow.
  * Returns the correction made to the indices, which must be applied to every
@@ -876,7 +876,7 @@ MEM_STATIC U32 ZSTD_window_correctOverflow(ZSTD_window_t* window, U32 cycleLog,
     return correction;
 }
 
-/**
+/*
  * ZSTD_window_enforceMaxDist():
  * Updates lowLimit so that:
  *    (srcEnd - base) - lowLimit == maxDist + loadedDictEnd
@@ -982,7 +982,7 @@ MEM_STATIC void ZSTD_window_init(ZSTD_window_t* window) {
     window->nextSrc = window->base + 1;   /* see issue #1241 */
 }
 
-/**
+/*
  * ZSTD_window_update():
  * Updates the window by appending [src, src + srcSize) to the window.
  * If it is not contiguous, the current prefix becomes the extDict, and we
@@ -1025,7 +1025,7 @@ MEM_STATIC U32 ZSTD_window_update(ZSTD_window_t* window,
     return contiguous;
 }
 
-/**
+/*
  * Returns the lowest allowed match index. It may either be in the ext-dict or the prefix.
  */
 MEM_STATIC U32 ZSTD_getLowestMatchIndex(const ZSTD_matchState_t* ms, U32 curr, unsigned windowLog)
@@ -1042,7 +1042,7 @@ MEM_STATIC U32 ZSTD_getLowestMatchIndex(const ZSTD_matchState_t* ms, U32 curr, u
     return matchLowest;
 }
 
-/**
+/*
  * Returns the lowest allowed match index in the prefix.
  */
 MEM_STATIC U32 ZSTD_getLowestPrefixIndex(const ZSTD_matchState_t* ms, U32 curr, unsigned windowLog)
@@ -1176,11 +1176,11 @@ size_t ZSTD_writeLastEmptyBlock(void* dst, size_t dstCapacity);
  */
 size_t ZSTD_referenceExternalSequences(ZSTD_CCtx* cctx, rawSeq* seq, size_t nbSeq);
 
-/** ZSTD_cycleLog() :
+/* ZSTD_cycleLog() :
  *  condition for correct operation : hashLog > 1 */
 U32 ZSTD_cycleLog(U32 hashLog, ZSTD_strategy strat);
 
-/** ZSTD_CCtx_trace() :
+/* ZSTD_CCtx_trace() :
  *  Trace the end of a compression call.
  */
 void ZSTD_CCtx_trace(ZSTD_CCtx* cctx, size_t extraCSize);
diff --git a/lib/zstd/compress/zstd_compress_sequences.c b/lib/zstd/compress/zstd_compress_sequences.c
index 08a5b8901..dcfcdc9cc 100644
--- a/lib/zstd/compress/zstd_compress_sequences.c
+++ b/lib/zstd/compress/zstd_compress_sequences.c
@@ -13,7 +13,7 @@
  ***************************************/
 #include "zstd_compress_sequences.h"
 
-/**
+/*
  * -log2(x / 256) lookup table for x in [0, 256).
  * If x == 0: Return 0
  * Else: Return floor(-log2(x / 256) * 256)
@@ -50,7 +50,7 @@ static unsigned ZSTD_getFSEMaxSymbolValue(FSE_CTable const* ctable) {
   return maxSymbolValue;
 }
 
-/**
+/*
  * Returns true if we should use ncount=-1 else we should
  * use ncount=1 for low probability symbols instead.
  */
@@ -63,7 +63,7 @@ static unsigned ZSTD_useLowProbCount(size_t const nbSeq)
     return nbSeq >= 2048;
 }
 
-/**
+/*
  * Returns the cost in bytes of encoding the normalized count header.
  * Returns an error if any of the helper functions return an error.
  */
@@ -77,7 +77,7 @@ static size_t ZSTD_NCountCost(unsigned const* count, unsigned const max,
     return FSE_writeNCount(wksp, sizeof(wksp), norm, max, tableLog);
 }
 
-/**
+/*
  * Returns the cost in bits of encoding the distribution described by count
  * using the entropy bound.
  */
@@ -95,7 +95,7 @@ static size_t ZSTD_entropyCost(unsigned const* count, unsigned const max, size_t
     return cost >> 8;
 }
 
-/**
+/*
  * Returns the cost in bits of encoding the distribution in count using ctable.
  * Returns an error if ctable cannot represent all the symbols in count.
  */
@@ -129,7 +129,7 @@ size_t ZSTD_fseBitCost(
     return cost >> kAccuracyLog;
 }
 
-/**
+/*
  * Returns the cost in bits of encoding the distribution in count using the
  * table described by norm. The max symbol support by norm is assumed >= max.
  * norm must be valid for every symbol with non-zero probability in count.
diff --git a/lib/zstd/compress/zstd_compress_superblock.c b/lib/zstd/compress/zstd_compress_superblock.c
index 767f73f5b..ee03e0aed 100644
--- a/lib/zstd/compress/zstd_compress_superblock.c
+++ b/lib/zstd/compress/zstd_compress_superblock.c
@@ -22,7 +22,7 @@
 /*-*************************************
 *  Superblock entropy buffer structs
 ***************************************/
-/** ZSTD_hufCTablesMetadata_t :
+/* ZSTD_hufCTablesMetadata_t :
  *  Stores Literals Block Type for a super-block in hType, and
  *  huffman tree description in hufDesBuffer.
  *  hufDesSize refers to the size of huffman tree description in bytes.
@@ -33,7 +33,7 @@ typedef struct {
     size_t hufDesSize;
 } ZSTD_hufCTablesMetadata_t;
 
-/** ZSTD_fseCTablesMetadata_t :
+/* ZSTD_fseCTablesMetadata_t :
  *  Stores symbol compression modes for a super-block in {ll, ol, ml}Type, and
  *  fse tables in fseTablesBuffer.
  *  fseTablesSize refers to the size of fse tables in bytes.
@@ -53,7 +53,7 @@ typedef struct {
 } ZSTD_entropyCTablesMetadata_t;
 
 
-/** ZSTD_buildSuperBlockEntropy_literal() :
+/* ZSTD_buildSuperBlockEntropy_literal() :
  *  Builds entropy for the super-block literals.
  *  Stores literals block type (raw, rle, compressed, repeat) and
  *  huffman description table to hufMetadata.
@@ -157,7 +157,7 @@ static size_t ZSTD_buildSuperBlockEntropy_literal(void* const src, size_t srcSiz
     }
 }
 
-/** ZSTD_buildSuperBlockEntropy_sequences() :
+/* ZSTD_buildSuperBlockEntropy_sequences() :
  *  Builds entropy for the super-block sequences.
  *  Stores symbol compression modes and fse table to fseMetadata.
  *  @return : size of fse tables or error code */
@@ -268,7 +268,7 @@ static size_t ZSTD_buildSuperBlockEntropy_sequences(seqStore_t* seqStorePtr,
 }
 
 
-/** ZSTD_buildSuperBlockEntropy() :
+/* ZSTD_buildSuperBlockEntropy() :
  *  Builds entropy for the super-block.
  *  @return : 0 on success or error code */
 static size_t
@@ -298,7 +298,7 @@ ZSTD_buildSuperBlockEntropy(seqStore_t* seqStorePtr,
     return 0;
 }
 
-/** ZSTD_compressSubBlock_literal() :
+/* ZSTD_compressSubBlock_literal() :
  *  Compresses literals section for a sub-block.
  *  When we have to write the Huffman table we will sometimes choose a header
  *  size larger than necessary. This is because we have to pick the header size
@@ -424,7 +424,7 @@ static size_t ZSTD_seqDecompressedSize(seqStore_t const* seqStore, const seqDef*
     return matchLengthSum + litSize;
 }
 
-/** ZSTD_compressSubBlock_sequences() :
+/* ZSTD_compressSubBlock_sequences() :
  *  Compresses sequences section for a sub-block.
  *  fseMetadata->llType, fseMetadata->ofType, and fseMetadata->mlType have
  *  symbol compression modes for the super-block.
@@ -530,7 +530,7 @@ static size_t ZSTD_compressSubBlock_sequences(const ZSTD_fseCTables_t* fseTables
     return op - ostart;
 }
 
-/** ZSTD_compressSubBlock() :
+/* ZSTD_compressSubBlock() :
  *  Compresses a single sub-block.
  *  @return : compressed size of the sub-block
  *            Or 0 if it failed to compress. */
@@ -692,7 +692,7 @@ static int ZSTD_needSequenceEntropyTables(ZSTD_fseCTablesMetadata_t const* fseMe
     return 0;
 }
 
-/** ZSTD_compressSubBlock_multi() :
+/* ZSTD_compressSubBlock_multi() :
  *  Breaks super-block into multiple sub-blocks and compresses them.
  *  Entropy will be written to the first block.
  *  The following blocks will use repeat mode to compress.
diff --git a/lib/zstd/compress/zstd_cwksp.h b/lib/zstd/compress/zstd_cwksp.h
index c231cc500..98e359adf 100644
--- a/lib/zstd/compress/zstd_cwksp.h
+++ b/lib/zstd/compress/zstd_cwksp.h
@@ -41,7 +41,7 @@ typedef enum {
     ZSTD_cwksp_alloc_aligned
 } ZSTD_cwksp_alloc_phase_e;
 
-/**
+/*
  * Used to describe whether the workspace is statically allocated (and will not
  * necessarily ever be freed), or if it's dynamically allocated and we can
  * expect a well-formed caller to free this.
@@ -51,7 +51,7 @@ typedef enum {
     ZSTD_cwksp_static_alloc
 } ZSTD_cwksp_static_alloc_e;
 
-/**
+/*
  * Zstd fits all its internal datastructures into a single continuous buffer,
  * so that it only needs to perform a single OS allocation (or so that a buffer
  * can be provided to it and it can perform no allocations at all). This buffer
@@ -166,7 +166,7 @@ MEM_STATIC void ZSTD_cwksp_assert_internal_consistency(ZSTD_cwksp* ws) {
     assert(ws->allocStart <= ws->workspaceEnd);
 }
 
-/**
+/*
  * Align must be a power of 2.
  */
 MEM_STATIC size_t ZSTD_cwksp_align(size_t size, size_t const align) {
@@ -175,7 +175,7 @@ MEM_STATIC size_t ZSTD_cwksp_align(size_t size, size_t const align) {
     return (size + mask) & ~mask;
 }
 
-/**
+/*
  * Use this to determine how much space in the workspace we will consume to
  * allocate this object. (Normally it should be exactly the size of the object,
  * but under special conditions, like ASAN, where we pad each object, it might
@@ -217,14 +217,14 @@ MEM_STATIC void ZSTD_cwksp_internal_advance_phase(
     }
 }
 
-/**
+/*
  * Returns whether this object/buffer/etc was allocated in this workspace.
  */
 MEM_STATIC int ZSTD_cwksp_owns_buffer(const ZSTD_cwksp* ws, const void* ptr) {
     return (ptr != NULL) && (ws->workspace <= ptr) && (ptr <= ws->workspaceEnd);
 }
 
-/**
+/*
  * Internal function. Do not use directly.
  */
 MEM_STATIC void* ZSTD_cwksp_reserve_internal(
@@ -256,14 +256,14 @@ MEM_STATIC void* ZSTD_cwksp_reserve_internal(
     return alloc;
 }
 
-/**
+/*
  * Reserves and returns unaligned memory.
  */
 MEM_STATIC BYTE* ZSTD_cwksp_reserve_buffer(ZSTD_cwksp* ws, size_t bytes) {
     return (BYTE*)ZSTD_cwksp_reserve_internal(ws, bytes, ZSTD_cwksp_alloc_buffers);
 }
 
-/**
+/*
  * Reserves and returns memory sized on and aligned on sizeof(unsigned).
  */
 MEM_STATIC void* ZSTD_cwksp_reserve_aligned(ZSTD_cwksp* ws, size_t bytes) {
@@ -271,7 +271,7 @@ MEM_STATIC void* ZSTD_cwksp_reserve_aligned(ZSTD_cwksp* ws, size_t bytes) {
     return ZSTD_cwksp_reserve_internal(ws, ZSTD_cwksp_align(bytes, sizeof(U32)), ZSTD_cwksp_alloc_aligned);
 }
 
-/**
+/*
  * Aligned on sizeof(unsigned). These buffers have the special property that
  * their values remain constrained, allowing us to re-use them without
  * memset()-ing them.
@@ -299,7 +299,7 @@ MEM_STATIC void* ZSTD_cwksp_reserve_table(ZSTD_cwksp* ws, size_t bytes) {
     return alloc;
 }
 
-/**
+/*
  * Aligned on sizeof(void*).
  */
 MEM_STATIC void* ZSTD_cwksp_reserve_object(ZSTD_cwksp* ws, size_t bytes) {
@@ -348,7 +348,7 @@ MEM_STATIC void ZSTD_cwksp_mark_tables_clean(ZSTD_cwksp* ws) {
     ZSTD_cwksp_assert_internal_consistency(ws);
 }
 
-/**
+/*
  * Zero the part of the allocated tables not already marked clean.
  */
 MEM_STATIC void ZSTD_cwksp_clean_tables(ZSTD_cwksp* ws) {
@@ -361,7 +361,7 @@ MEM_STATIC void ZSTD_cwksp_clean_tables(ZSTD_cwksp* ws) {
     ZSTD_cwksp_mark_tables_clean(ws);
 }
 
-/**
+/*
  * Invalidates table allocations.
  * All other allocations remain valid.
  */
@@ -373,7 +373,7 @@ MEM_STATIC void ZSTD_cwksp_clear_tables(ZSTD_cwksp* ws) {
     ZSTD_cwksp_assert_internal_consistency(ws);
 }
 
-/**
+/*
  * Invalidates all buffer, aligned, and table allocations.
  * Object allocations remain valid.
  */
@@ -391,7 +391,7 @@ MEM_STATIC void ZSTD_cwksp_clear(ZSTD_cwksp* ws) {
     ZSTD_cwksp_assert_internal_consistency(ws);
 }
 
-/**
+/*
  * The provided workspace takes ownership of the buffer [start, start+size).
  * Any existing values in the workspace are ignored (the previously managed
  * buffer, if present, must be separately freed).
@@ -425,7 +425,7 @@ MEM_STATIC void ZSTD_cwksp_free(ZSTD_cwksp* ws, ZSTD_customMem customMem) {
     ZSTD_customFree(ptr, customMem);
 }
 
-/**
+/*
  * Moves the management of a workspace from one cwksp to another. The src cwksp
  * is left in an invalid state (src must be re-init()'ed before it's used again).
  */
diff --git a/lib/zstd/compress/zstd_lazy.c b/lib/zstd/compress/zstd_lazy.c
index 39aa2569a..87cfa353a 100644
--- a/lib/zstd/compress/zstd_lazy.c
+++ b/lib/zstd/compress/zstd_lazy.c
@@ -56,7 +56,7 @@ ZSTD_updateDUBT(ZSTD_matchState_t* ms,
 }
 
 
-/** ZSTD_insertDUBT1() :
+/* ZSTD_insertDUBT1() :
  *  sort one already inserted but unsorted position
  *  assumption : curr >= btlow == (curr - btmask)
  *  doesn't fail */
@@ -376,7 +376,7 @@ ZSTD_DUBT_findBestMatch(ZSTD_matchState_t* ms,
 }
 
 
-/** ZSTD_BtFindBestMatch() : Tree updater, providing best match */
+/* ZSTD_BtFindBestMatch() : Tree updater, providing best match */
 FORCE_INLINE_TEMPLATE size_t
 ZSTD_BtFindBestMatch( ZSTD_matchState_t* ms,
                 const BYTE* const ip, const BYTE* const iLimit,
@@ -872,7 +872,7 @@ ZSTD_compressBlock_lazy_generic(
                         ZSTD_matchState_t* ms,
                         const BYTE* ip, const BYTE* iLimit, size_t* offsetPtr);
 
-    /**
+    /*
      * This table is indexed first by the four ZSTD_dictMode_e values, and then
      * by the two searchMethod_e values. NULLs are placed for configurations
      * that should never occur (extDict modes go to the other implementation
diff --git a/lib/zstd/compress/zstd_lazy.h b/lib/zstd/compress/zstd_lazy.h
index 1fb7621e6..2fc5a6182 100644
--- a/lib/zstd/compress/zstd_lazy.h
+++ b/lib/zstd/compress/zstd_lazy.h
@@ -14,7 +14,7 @@
 
 #include "zstd_compress_internal.h"
 
-/**
+/*
  * Dedicated Dictionary Search Structure bucket log. In the
  * ZSTD_dedicatedDictSearch mode, the hashTable has
  * 2 ** ZSTD_LAZY_DDSS_BUCKET_LOG entries in each bucket, rather than just
diff --git a/lib/zstd/compress/zstd_ldm.c b/lib/zstd/compress/zstd_ldm.c
index 4b786fe1c..8ef7e88a5 100644
--- a/lib/zstd/compress/zstd_ldm.c
+++ b/lib/zstd/compress/zstd_ldm.c
@@ -25,7 +25,7 @@ typedef struct {
     U64 stopMask;
 } ldmRollingHashState_t;
 
-/** ZSTD_ldm_gear_init():
+/* ZSTD_ldm_gear_init():
  *
  * Initializes the rolling hash state such that it will honor the
  * settings in params. */
@@ -57,7 +57,7 @@ static void ZSTD_ldm_gear_init(ldmRollingHashState_t* state, ldmParams_t const*
     }
 }
 
-/** ZSTD_ldm_gear_feed():
+/* ZSTD_ldm_gear_feed():
  *
  * Registers in the splits array all the split points found in the first
  * size bytes following the data pointer. This function terminates when
@@ -140,7 +140,7 @@ size_t ZSTD_ldm_getMaxNbSeq(ldmParams_t params, size_t maxChunkSize)
     return params.enableLdm ? (maxChunkSize / params.minMatchLength) : 0;
 }
 
-/** ZSTD_ldm_getBucket() :
+/* ZSTD_ldm_getBucket() :
  *  Returns a pointer to the start of the bucket associated with hash. */
 static ldmEntry_t* ZSTD_ldm_getBucket(
         ldmState_t* ldmState, size_t hash, ldmParams_t const ldmParams)
@@ -148,7 +148,7 @@ static ldmEntry_t* ZSTD_ldm_getBucket(
     return ldmState->hashTable + (hash << ldmParams.bucketSizeLog);
 }
 
-/** ZSTD_ldm_insertEntry() :
+/* ZSTD_ldm_insertEntry() :
  *  Insert the entry with corresponding hash into the hash table */
 static void ZSTD_ldm_insertEntry(ldmState_t* ldmState,
                                  size_t const hash, const ldmEntry_t entry,
@@ -162,7 +162,7 @@ static void ZSTD_ldm_insertEntry(ldmState_t* ldmState,
 
 }
 
-/** ZSTD_ldm_countBackwardsMatch() :
+/* ZSTD_ldm_countBackwardsMatch() :
  *  Returns the number of bytes that match backwards before pIn and pMatch.
  *
  *  We count only bytes where pMatch >= pBase and pIn >= pAnchor. */
@@ -179,7 +179,7 @@ static size_t ZSTD_ldm_countBackwardsMatch(
     return matchLength;
 }
 
-/** ZSTD_ldm_countBackwardsMatch_2segments() :
+/* ZSTD_ldm_countBackwardsMatch_2segments() :
  *  Returns the number of bytes that match backwards from pMatch,
  *  even with the backwards match spanning 2 different segments.
  *
@@ -200,7 +200,7 @@ static size_t ZSTD_ldm_countBackwardsMatch_2segments(
     return matchLength;
 }
 
-/** ZSTD_ldm_fillFastTables() :
+/* ZSTD_ldm_fillFastTables() :
  *
  *  Fills the relevant tables for the ZSTD_fast and ZSTD_dfast strategies.
  *  This is similar to ZSTD_loadDictionaryContent.
@@ -277,7 +277,7 @@ void ZSTD_ldm_fillHashTable(
 }
 
 
-/** ZSTD_ldm_limitTableUpdate() :
+/* ZSTD_ldm_limitTableUpdate() :
  *
  *  Sets cctx->nextToUpdate to a position corresponding closer to anchor
  *  if it is far way
@@ -572,7 +572,7 @@ void ZSTD_ldm_skipSequences(rawSeqStore_t* rawSeqStore, size_t srcSize, U32 cons
     }
 }
 
-/**
+/*
  * If the sequence length is longer than remaining then the sequence is split
  * between this block and the next.
  *
diff --git a/lib/zstd/compress/zstd_ldm.h b/lib/zstd/compress/zstd_ldm.h
index 5ee467eac..25b25270b 100644
--- a/lib/zstd/compress/zstd_ldm.h
+++ b/lib/zstd/compress/zstd_ldm.h
@@ -25,7 +25,7 @@ void ZSTD_ldm_fillHashTable(
             ldmState_t* state, const BYTE* ip,
             const BYTE* iend, ldmParams_t const* params);
 
-/**
+/*
  * ZSTD_ldm_generateSequences():
  *
  * Generates the sequences using the long distance match finder.
@@ -43,7 +43,7 @@ size_t ZSTD_ldm_generateSequences(
             ldmState_t* ldms, rawSeqStore_t* sequences,
             ldmParams_t const* params, void const* src, size_t srcSize);
 
-/**
+/*
  * ZSTD_ldm_blockCompress():
  *
  * Compresses a block using the predefined sequences, along with a secondary
@@ -65,7 +65,7 @@ size_t ZSTD_ldm_blockCompress(rawSeqStore_t* rawSeqStore,
             ZSTD_matchState_t* ms, seqStore_t* seqStore, U32 rep[ZSTD_REP_NUM],
             void const* src, size_t srcSize);
 
-/**
+/*
  * ZSTD_ldm_skipSequences():
  *
  * Skip past `srcSize` bytes worth of sequences in `rawSeqStore`.
@@ -82,19 +82,19 @@ void ZSTD_ldm_skipSequences(rawSeqStore_t* rawSeqStore, size_t srcSize,
  */
 void ZSTD_ldm_skipRawSeqStoreBytes(rawSeqStore_t* rawSeqStore, size_t nbBytes);
 
-/** ZSTD_ldm_getTableSize() :
+/* ZSTD_ldm_getTableSize() :
  *  Estimate the space needed for long distance matching tables or 0 if LDM is
  *  disabled.
  */
 size_t ZSTD_ldm_getTableSize(ldmParams_t params);
 
-/** ZSTD_ldm_getSeqSpace() :
+/* ZSTD_ldm_getSeqSpace() :
  *  Return an upper bound on the number of sequences that can be produced by
  *  the long distance matcher, or 0 if LDM is disabled.
  */
 size_t ZSTD_ldm_getMaxNbSeq(ldmParams_t params, size_t maxChunkSize);
 
-/** ZSTD_ldm_adjustParameters() :
+/* ZSTD_ldm_adjustParameters() :
  *  If the params->hashRateLog is not set, set it to its default value based on
  *  windowLog and params->hashLog.
  *
diff --git a/lib/zstd/compress/zstd_opt.c b/lib/zstd/compress/zstd_opt.c
index 402a7e5c7..956ee6b2a 100644
--- a/lib/zstd/compress/zstd_opt.c
+++ b/lib/zstd/compress/zstd_opt.c
@@ -363,7 +363,7 @@ static U32 ZSTD_insertAndFindFirstIndexHash3 (ZSTD_matchState_t* ms,
 /*-*************************************
 *  Binary Tree search
 ***************************************/
-/** ZSTD_insertBt1() : add one or multiple positions to tree.
+/* ZSTD_insertBt1() : add one or multiple positions to tree.
  *  ip : assumed <= iend-8 .
  * @return : nb of positions added */
 static U32 ZSTD_insertBt1(
@@ -764,7 +764,7 @@ FORCE_INLINE_TEMPLATE U32 ZSTD_BtGetAllMatches (
     }
 }
 
-/*************************
+/* ***********************
 *  LDM helper functions  *
 *************************/
 
diff --git a/lib/zstd/decompress/huf_decompress.c b/lib/zstd/decompress/huf_decompress.c
index c48d57e3f..05570ed5f 100644
--- a/lib/zstd/decompress/huf_decompress.c
+++ b/lib/zstd/decompress/huf_decompress.c
@@ -115,7 +115,7 @@ static DTableDesc HUF_getDTableDesc(const HUF_DTable* table)
 /*-***************************/
 typedef struct { BYTE byte; BYTE nbBits; } HUF_DEltX1;   /* single-symbol decoding */
 
-/**
+/*
  * Packs 4 HUF_DEltX1 structs into a U64. This is used to lay down 4 entries at
  * a time.
  */
@@ -1047,7 +1047,7 @@ static const algo_time_t algoTime[16 /* Quantization */][3 /* single, double, qu
 };
 #endif
 
-/** HUF_selectDecoder() :
+/* HUF_selectDecoder() :
  *  Tells which decoder is likely to decode faster,
  *  based on a set of pre-computed metrics.
  * @return : 0==HUF_decompress4X1, 1==HUF_decompress4X2 .
diff --git a/lib/zstd/decompress/zstd_decompress.c b/lib/zstd/decompress/zstd_decompress.c
index 16b4ea795..099f708ac 100644
--- a/lib/zstd/decompress/zstd_decompress.c
+++ b/lib/zstd/decompress/zstd_decompress.c
@@ -68,7 +68,7 @@
 
 
 
-/*************************************
+/* ***********************************
  * Multiple DDicts Hashset internals *
  *************************************/
 
@@ -367,7 +367,7 @@ unsigned ZSTD_isFrame(const void* buffer, size_t size)
     return 0;
 }
 
-/** ZSTD_frameHeaderSize_internal() :
+/* ZSTD_frameHeaderSize_internal() :
  *  srcSize must be large enough to reach header size fields.
  *  note : only works for formats ZSTD_f_zstd1 and ZSTD_f_zstd1_magicless.
  * @return : size of the Frame Header
@@ -387,7 +387,7 @@ static size_t ZSTD_frameHeaderSize_internal(const void* src, size_t srcSize, ZST
     }
 }
 
-/** ZSTD_frameHeaderSize() :
+/* ZSTD_frameHeaderSize() :
  *  srcSize must be >= ZSTD_frameHeaderSize_prefix.
  * @return : size of the Frame Header,
  *           or an error code (if srcSize is too small) */
@@ -397,7 +397,7 @@ size_t ZSTD_frameHeaderSize(const void* src, size_t srcSize)
 }
 
 
-/** ZSTD_getFrameHeader_advanced() :
+/* ZSTD_getFrameHeader_advanced() :
  *  decode Frame Header, or require larger `srcSize`.
  *  note : only works for formats ZSTD_f_zstd1 and ZSTD_f_zstd1_magicless
  * @return : 0, `zfhPtr` is correctly filled,
@@ -479,7 +479,7 @@ size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr, const void* src, s
     return 0;
 }
 
-/** ZSTD_getFrameHeader() :
+/* ZSTD_getFrameHeader() :
  *  decode Frame Header, or require larger `srcSize`.
  *  note : this function does not consume input, it only reads it.
  * @return : 0, `zfhPtr` is correctly filled,
@@ -491,7 +491,7 @@ size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t src
 }
 
 
-/** ZSTD_getFrameContentSize() :
+/* ZSTD_getFrameContentSize() :
  *  compatible with legacy mode
  * @return : decompressed size of the single frame pointed to be `src` if known, otherwise
  *         - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined
@@ -525,7 +525,7 @@ static size_t readSkippableFrameSize(void const* src, size_t srcSize)
     }
 }
 
-/** ZSTD_findDecompressedSize() :
+/* ZSTD_findDecompressedSize() :
  *  compatible with legacy mode
  *  `srcSize` must be the exact length of some number of ZSTD compressed and/or
  *      skippable frames
@@ -571,7 +571,7 @@ unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize)
     return totalDstSize;
 }
 
-/** ZSTD_getDecompressedSize() :
+/* ZSTD_getDecompressedSize() :
  *  compatible with legacy mode
  * @return : decompressed size if known, 0 otherwise
              note : 0 can mean any of the following :
@@ -587,7 +587,7 @@ unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize)
 }
 
 
-/** ZSTD_decodeFrameHeader() :
+/* ZSTD_decodeFrameHeader() :
  * `headerSize` must be the size provided by ZSTD_frameHeaderSize().
  * If multiple DDict references are enabled, also will choose the correct DDict to use.
  * @return : 0 if success, or an error code, which can be tested using ZSTD_isError() */
@@ -685,7 +685,7 @@ static ZSTD_frameSizeInfo ZSTD_findFrameSizeInfo(const void* src, size_t srcSize
     }
 }
 
-/** ZSTD_findFrameCompressedSize() :
+/* ZSTD_findFrameCompressedSize() :
  *  compatible with legacy mode
  *  `src` must point to the start of a ZSTD frame, ZSTD legacy frame, or skippable frame
  *  `srcSize` must be at least as large as the frame contained
@@ -696,7 +696,7 @@ size_t ZSTD_findFrameCompressedSize(const void *src, size_t srcSize)
     return frameSizeInfo.compressedSize;
 }
 
-/** ZSTD_decompressBound() :
+/* ZSTD_decompressBound() :
  *  compatible with legacy mode
  *  `src` must point to the start of a ZSTD frame or a skippeable frame
  *  `srcSize` must be at least as large as the frame contained
@@ -725,7 +725,7 @@ unsigned long long ZSTD_decompressBound(const void* src, size_t srcSize)
  *   Frame decoding
  ***************************************************************/
 
-/** ZSTD_insertBlock() :
+/* ZSTD_insertBlock() :
  *  insert `src` block into `dctx` history. Useful to track uncompressed blocks. */
 size_t ZSTD_insertBlock(ZSTD_DCtx* dctx, const void* blockStart, size_t blockSize)
 {
@@ -988,7 +988,7 @@ size_t ZSTD_decompress(void* dst, size_t dstCapacity, const void* src, size_t sr
 ****************************************/
 size_t ZSTD_nextSrcSizeToDecompress(ZSTD_DCtx* dctx) { return dctx->expected; }
 
-/**
+/*
  * Similar to ZSTD_nextSrcSizeToDecompress(), but when when a block input can be streamed,
  * we allow taking a partial block as the input. Currently only raw uncompressed blocks can
  * be streamed.
@@ -1030,7 +1030,7 @@ ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx* dctx) {
 
 static int ZSTD_isSkipFrame(ZSTD_DCtx* dctx) { return dctx->stage == ZSTDds_skipFrame; }
 
-/** ZSTD_decompressContinue() :
+/* ZSTD_decompressContinue() :
  *  srcSize : must be the exact nb of bytes expected (see ZSTD_nextSrcSizeToDecompress())
  *  @return : nb of bytes generated into `dst` (necessarily <= `dstCapacity)
  *            or an error code, which can be tested using ZSTD_isError() */
-- 
2.31.1.362.g311531c9de

