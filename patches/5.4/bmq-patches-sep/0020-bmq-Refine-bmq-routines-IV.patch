From a5169993a3440d36ca5f40ee09a3fee355caba53 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Mon, 29 Jul 2019 09:43:00 +0800
Subject: [PATCH 20/53] bmq: Refine bmq routines IV

---
 kernel/sched/bmq.c | 9 +++------
 1 file changed, 3 insertions(+), 6 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index 0c00e00b7aca..c5ed01de2b79 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -468,7 +468,6 @@ static void update_rq_clock_task(struct rq *rq, s64 delta)
 			steal = delta;
 
 		rq->prev_steal_time_rq += steal;
-
 		delta -= steal;
 	}
 #endif
@@ -1073,9 +1072,8 @@ static int migration_cpu_stop(void *data)
 	 * holding rq->lock, if p->on_rq == 0 it cannot get enqueued because
 	 * we're holding p->pi_lock.
 	 */
-	if (task_rq(p) == rq)
-		if (task_on_rq_queued(p))
-			rq = __migrate_task(rq, p, arg->dest_cpu);
+	if (task_rq(p) == rq && task_on_rq_queued(p))
+		rq = __migrate_task(rq, p, arg->dest_cpu);
 	raw_spin_unlock(&rq->lock);
 	raw_spin_unlock(&p->pi_lock);
 
@@ -2471,7 +2469,7 @@ static inline int active_load_balance_cpu_stop(void *data)
 	/* _something_ may have changed the task, double check again */
 	if (task_on_rq_queued(p) && task_rq(p) == rq &&
 	    (cpu = cpumask_any_and(p->cpus_ptr, &sched_rq_watermark[0])) < nr_cpu_ids)
-		rq = __migrate_task(rq, p, cpu);
+		rq = move_queued_task(rq, p, cpu);
 
 	raw_spin_unlock(&rq->lock);
 	raw_spin_unlock(&p->pi_lock);
@@ -5214,7 +5212,6 @@ static void migrate_tasks(struct rq *dead_rq)
 		count++;
 		/* Find suitable destination for @next, with force if needed. */
 		dest_cpu = select_fallback_rq(dead_rq->cpu, p);
-
 		rq = __migrate_task(rq, p, dest_cpu);
 		raw_spin_unlock(&rq->lock);
 		raw_spin_unlock(&p->pi_lock);
-- 
2.24.0.155.gd9f6f3b619

