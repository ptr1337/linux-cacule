From 49e4c8fc7e8882ee53659ee85fbabbb3e18a092a Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Fri, 2 Aug 2019 15:12:30 +0800
Subject: [PATCH 22/53] bmq: Consider llc in sg balance code path.

---
 kernel/sched/bmq.c | 21 ++++++++++-----------
 1 file changed, 10 insertions(+), 11 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index 4737772051b2..81a50e851dd2 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -1331,20 +1331,19 @@ static int select_fallback_rq(int cpu, struct task_struct *p)
 	return dest_cpu;
 }
 
-static inline int best_mask_cpu(int cpu, cpumask_t *cpumask)
+static inline int __best_mask_cpu(int cpu, cpumask_t *cpumask)
 {
-	cpumask_t *mask;
-
-	if (cpumask_test_cpu(cpu, cpumask))
-		return cpu;
-
-	mask = &(per_cpu(sched_cpu_affinity_chk_masks, cpu)[0]);
+	cpumask_t *mask = &(per_cpu(sched_cpu_affinity_chk_masks, cpu)[0]);
 	while ((cpu = cpumask_any_and(cpumask, mask)) >= nr_cpu_ids)
 		mask++;
-
 	return cpu;
 }
 
+static inline int best_mask_cpu(int cpu, cpumask_t *cpumask)
+{
+	return cpumask_test_cpu(cpu, cpumask)? cpu:__best_mask_cpu(cpu, cpumask);
+}
+
 /*
  * wake flags
  */
@@ -2466,7 +2465,7 @@ static inline int active_load_balance_cpu_stop(void *data)
 {
 	struct rq *rq = this_rq();
 	struct task_struct *p = data;
-	int cpu;
+	cpumask_t tmp;
 	unsigned long flags;
 
 	local_irq_save(flags);
@@ -2477,8 +2476,8 @@ static inline int active_load_balance_cpu_stop(void *data)
 	rq->active_balance = 0;
 	/* _something_ may have changed the task, double check again */
 	if (task_on_rq_queued(p) && task_rq(p) == rq &&
-	    (cpu = cpumask_any_and(p->cpus_ptr, &sched_rq_watermark[0])) < nr_cpu_ids)
-		rq = move_queued_task(rq, p, cpu);
+	    cpumask_and(&tmp, p->cpus_ptr, &sched_rq_watermark[0]))
+		rq = move_queued_task(rq, p, __best_mask_cpu(cpu_of(rq), &tmp));
 
 	raw_spin_unlock(&rq->lock);
 	raw_spin_unlock(&p->pi_lock);
-- 
2.24.0.155.gd9f6f3b619

