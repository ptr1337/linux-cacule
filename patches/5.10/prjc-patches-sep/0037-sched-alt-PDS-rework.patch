From 8e869a958cd3cfa50d93bf83bd8855f704ad020b Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Sat, 5 Sep 2020 16:25:49 +0800
Subject: [PATCH 37/79] sched/alt: PDS rework.

alt:
Rework bmq&pds routine in sched_fork().
Sync-up mainline implement in sched_exec(), add task pi locking.
Add alt_sched_debug() and control by ALT_SCHED_DEBUG macro.

pds:
Update user_prio2deadline which now based on default 4ms time slice.
Update dl_level_map which provides 20 levels instead of the original 8
levels.
Fix issue that task_sched_prio() doesn't return corrent sched prio for
idle task.
Implement sched_task_for() routine.
---
 kernel/sched/alt_core.c  | 57 ++++++++++++++++++++++++++++------------
 kernel/sched/alt_debug.c |  2 +-
 kernel/sched/bmq_imp.h   |  2 +-
 kernel/sched/pds.h       |  2 +-
 kernel/sched/pds_imp.h   | 52 +++++++++++++++++++++++++-----------
 5 files changed, 79 insertions(+), 36 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 5187d23f27df..091f6919195c 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -2172,9 +2172,7 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 		 */
 		p->sched_reset_on_fork = 0;
 	}
-	update_task_priodl(p);
 
-	sched_task_fork(p);
 	/*
 	 * The child is not yet in the pid-hash so no cgroup attach races,
 	 * and the cgroup is pinned to this child due to cgroup_fork()
@@ -2190,6 +2188,7 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 	 */
 	rq = this_rq();
 	raw_spin_lock(&rq->lock);
+
 	rq->curr->time_slice /= 2;
 	p->time_slice = rq->curr->time_slice;
 #ifdef CONFIG_SCHED_HRTICK
@@ -2197,9 +2196,10 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 #endif
 
 	if (p->time_slice < RESCHED_NS) {
-		time_slice_expired(p, rq);
+		p->time_slice = sched_timeslice_ns;
 		resched_curr(rq);
 	}
+	sched_task_fork(p, rq);
 	raw_spin_unlock(&rq->lock);
 
 	rseq_migrate(p);
@@ -2795,25 +2795,29 @@ unsigned long nr_iowait(void)
 void sched_exec(void)
 {
 	struct task_struct *p = current;
+	unsigned long flags;
 	int dest_cpu;
+	struct rq *rq;
 
-	if (task_rq(p)->nr_running < 2)
-		return;
+	raw_spin_lock_irqsave(&p->pi_lock, flags);
+	rq = this_rq();
 
-	dest_cpu = cpumask_any_and(p->cpus_ptr, &sched_rq_watermark[IDLE_WM]);
-	if ( dest_cpu < nr_cpu_ids) {
-#ifdef CONFIG_SCHED_SMT
-		int smt = cpumask_any_and(p->cpus_ptr, &sched_sg_idle_mask);
-		if (smt < nr_cpu_ids)
-			dest_cpu = smt;
-#endif
-		if (likely(cpu_active(dest_cpu))) {
-			struct migration_arg arg = { p, dest_cpu };
+	if (rq != task_rq(p) || rq->nr_running < 2)
+		goto unlock;
 
-			stop_one_cpu(task_cpu(p), migration_cpu_stop, &arg);
-			return;
-		}
+	dest_cpu = select_task_rq(p, task_rq(p));
+	if (dest_cpu == smp_processor_id())
+		goto unlock;
+
+	if (likely(cpu_active(dest_cpu))) {
+		struct migration_arg arg = { p, dest_cpu };
+
+		raw_spin_unlock_irqrestore(&p->pi_lock, flags);
+		stop_one_cpu(task_cpu(p), migration_cpu_stop, &arg);
+		return;
 	}
+unlock:
+	raw_spin_unlock_irqrestore(&p->pi_lock, flags);
 }
 
 #endif
@@ -3314,6 +3318,23 @@ static inline void schedule_debug(struct task_struct *prev, bool preempt)
 	schedstat_inc(this_rq()->sched_count);
 }
 
+/*
+ * Compile time debug macro
+ * #define ALT_SCHED_DEBUG
+ */
+
+#ifdef ALT_SCHED_DEBUG
+void alt_sched_debug(void)
+{
+	printk(KERN_INFO "sched: pending: 0x%04lx, idle: 0x%04lx, sg_idle: 0x%04lx\n",
+	       sched_rq_pending_mask.bits[0],
+	       sched_rq_watermark[IDLE_WM].bits[0],
+	       sched_sg_idle_mask.bits[0]);
+}
+#else
+inline void alt_sched_debug(void) {}
+#endif
+
 #ifdef	CONFIG_SMP
 
 #define SCHED_RQ_NR_MIGRATION (32UL)
@@ -5153,6 +5174,8 @@ static int sched_rr_get_interval(pid_t pid, struct timespec64 *t)
 	struct task_struct *p;
 	int retval;
 
+	alt_sched_debug();
+
 	if (pid < 0)
 		return -EINVAL;
 
diff --git a/kernel/sched/alt_debug.c b/kernel/sched/alt_debug.c
index 835e6bb98dda..1212a031700e 100644
--- a/kernel/sched/alt_debug.c
+++ b/kernel/sched/alt_debug.c
@@ -1,7 +1,7 @@
 /*
  * kernel/sched/alt_debug.c
  *
- * Print the BMQ debugging details
+ * Print the alt scheduler debugging details
  *
  * Author: Alfred Chen
  * Date  : 2020
diff --git a/kernel/sched/bmq_imp.h b/kernel/sched/bmq_imp.h
index c9f0c708dd61..0e67e00a6020 100644
--- a/kernel/sched/bmq_imp.h
+++ b/kernel/sched/bmq_imp.h
@@ -146,7 +146,7 @@ static inline bool sched_task_need_requeue(struct task_struct *p, struct rq *rq)
 	return (task_sched_prio(p, rq) != p->bmq_idx);
 }
 
-static void sched_task_fork(struct task_struct *p)
+static void sched_task_fork(struct task_struct *p, struct rq *rq)
 {
 	p->boost_prio = (p->boost_prio < 0) ?
 		p->boost_prio + MAX_PRIORITY_ADJ : MAX_PRIORITY_ADJ;
diff --git a/kernel/sched/pds.h b/kernel/sched/pds.h
index 9b9addc205a9..7fdeace7e8a5 100644
--- a/kernel/sched/pds.h
+++ b/kernel/sched/pds.h
@@ -3,7 +3,7 @@
 
 /* bits:
  * RT(0-99), (Low prio adj range, nice width, high prio adj range) / 2, cpu idle task */
-#define SCHED_BITS	(MAX_RT_PRIO + MAX_PRIORITY_ADJ * 2 + 8 + 1)
+#define SCHED_BITS	(MAX_RT_PRIO + 20 + 1)
 #define IDLE_TASK_SCHED_PRIO	(SCHED_BITS - 1)
 
 static inline int task_running_nice(struct task_struct *p)
diff --git a/kernel/sched/pds_imp.h b/kernel/sched/pds_imp.h
index aa7e933f08b8..4a2fc8993229 100644
--- a/kernel/sched/pds_imp.h
+++ b/kernel/sched/pds_imp.h
@@ -1,31 +1,46 @@
 #define ALT_SCHED_VERSION_MSG "sched/bmq: PDS CPU Scheduler 5.8-r0 by Alfred Chen.\n"
 
 static const u64 user_prio2deadline[NICE_WIDTH] = {
-/* -20 */	  6291456,   6920601,   7612661,   8373927,   9211319,
-/* -15 */	 10132450,  11145695,  12260264,  13486290,  14834919,
-/* -10 */	 16318410,  17950251,  19745276,  21719803,  23891783,
-/*  -5 */	 26280961,  28909057,  31799962,  34979958,  38477953,
-/*   0 */	 42325748,  46558322,  51214154,  56335569,  61969125,
-/*   5 */	 68166037,  74982640,  82480904,  90728994,  99801893,
-/*  10 */	109782082, 120760290, 132836319, 146119950, 160731945,
-/*  15 */	176805139, 194485652, 213934217, 235327638, 258860401
+/* -20 */	  4194304,   4613734,   5075107,   5582617,   6140878,
+/* -15 */	  6754965,   7430461,   8173507,   8990857,   9889942,
+/* -10 */	 10878936,  11966829,  13163511,  14479862,  15927848,
+/*  -5 */	 17520632,  19272695,  21199964,  23319960,  25651956,
+/*   0 */	 28217151,  31038866,  34142752,  37557027,  41312729,
+/*   5 */	 45444001,  49988401,  54987241,  60485965,  66534561,
+/*  10 */	 73188017,  80506818,  88557499,  97413248, 107154572,
+/*  15 */	117870029, 129657031, 142622734, 156885007, 172573507
 };
 
-static const int dl_level_map[] = {
-/*      0           4           8           12           */
-	0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,
-/*      16          20          24          28           */
-	1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 6, 7
+static const unsigned char dl_level_map[] = {
+/*       0               4               8              12           */
+	19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 18,
+/*      16              20              24              28           */
+	18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17,
+/*      32              36              40              44           */
+	17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15,
+/*      48              52              56              60           */
+	15, 15, 15, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 12, 12, 12,
+/*      64              68              72              76           */
+	12, 11, 11, 11, 10, 10, 10,  9,  9,  8,  7,  6,  5,  4,  3,  2,
+/*      80              84              88              92           */
+	 1,  0
 };
 
 static inline int
 task_sched_prio(const struct task_struct *p, const struct rq *rq)
 {
-	u64 delta = (rq->clock + user_prio2deadline[39] - p->deadline) >> 23;
+	size_t delta;
 
+	if (p == rq->idle)
+		return IDLE_TASK_SCHED_PRIO;
+
+	if (p->prio < MAX_RT_PRIO)
+		return p->prio;
+
+	delta = (rq->clock + user_prio2deadline[39] - p->deadline) >> 21;
 	delta = min((size_t)delta, ARRAY_SIZE(dl_level_map) - 1);
 
-	return (p->prio < MAX_RT_PRIO)? p->prio : MAX_RT_PRIO + dl_level_map[delta];
+	return MAX_RT_PRIO + dl_level_map[delta];
 }
 
 static inline void update_task_priodl(struct task_struct *p)
@@ -173,7 +188,12 @@ static inline bool sched_task_need_requeue(struct task_struct *p, struct rq *rq)
 	return false;
 }
 
-static void sched_task_fork(struct task_struct *p) {}
+static void sched_task_fork(struct task_struct *p, struct rq *rq)
+{
+	if (p->prio >= MAX_RT_PRIO)
+		p->deadline = rq->clock + user_prio2deadline[TASK_USER_PRIO(p)];
+	update_task_priodl(p);
+}
 
 /**
  * task_prio - return the priority value of a given task.
-- 
2.29.2.456.g3a0b884cab

